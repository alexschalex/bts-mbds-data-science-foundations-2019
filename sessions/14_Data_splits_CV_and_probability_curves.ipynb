{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "14_Data_splits_CV_and_probability_curves.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_a2hajcA99-K",
        "colab_type": "text"
      },
      "source": [
        "![BTS](https://github.com/vfp1/bts-mbds-data-science-foundations-2019/raw/master/sessions/img/Logo-BTS.jpg)\n",
        "\n",
        "# Session 14: Model validation cted. and algorithms\n",
        "### Victor F. Pajuelo Madrigal <victor.pajuelo@bts.tech> - Data Science Foundations (2019-11-28)\n",
        "\n",
        "Open this notebook in Google Colaboratory: [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/vfp1/bts-mbds-data-science-foundations-2019/blob/master/sessions/14_Data_splits_CV_and_probability_curves.ipynb)\n",
        "\n",
        "**Resources:**\n",
        "\n",
        "*   Jake VanderPlass\n",
        "*   Machine Learning Mastery\n",
        "*   Sklearn documentation\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkHo9i0eCXn2",
        "colab_type": "text"
      },
      "source": [
        "# About the next sessions\n",
        "\n",
        "*   Model validation\n",
        "*   In depth algorithms\n",
        "*   Data scrapping, gathering\n",
        "*   Project to product: Docker and app release"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKkKVRcn7-kf",
        "colab_type": "text"
      },
      "source": [
        "# Data splits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsb-wj1jBGAQ",
        "colab_type": "text"
      },
      "source": [
        "*The literature on machine learning often reverses the meaning of “validation” and “test” sets. This is the most blatant example of the terminological confusion that pervades artificial intelligence research.*\n",
        "\n",
        "*The crucial point is that a test set, by the standard definition in the NN [neural net] literature, is never used to choose among two or more networks, so that the error on the test set provides an unbiased estimate of the generalization error (assuming that the test set is representative of the population, etc.).*\n",
        "\n",
        "\n",
        "* **Training Dataset**: The sample of data used to fit the model.\n",
        "* **Validation Dataset**: The sample of data used to provide an unbiased evaluation of a model fit on the training dataset while tuning model hyperparameters. The evaluation becomes more biased as skill on the validation dataset is incorporated into the model configuration.\n",
        "* **Test Dataset**: The sample of data used to provide an unbiased evaluation of a final model fit on the training dataset.\n",
        "\n",
        "We can make this concrete with a pseudocode sketch:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stmUmfBD8AwE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split data\n",
        "data = ...\n",
        "train, validation, test = split(data)\n",
        " \n",
        "# tune model hyperparameters\n",
        "parameters = ...\n",
        "for params in parameters:\n",
        "\tmodel = fit(train, params)\n",
        "\tskill = evaluate(model, validation)\n",
        " \n",
        "# evaluate final model for comparison with other models\n",
        "model = fit(train)\n",
        "skill = evaluate(model, test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLbRQVNdjsdY",
        "colab_type": "text"
      },
      "source": [
        "## Important note on jargon!!!\n",
        "\n",
        "* **Model evaluation** is done with the `test split`\n",
        "* **Model validation** is done with the `validation split` (extracted from train)\n",
        "* **Model training** is done with the training split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Z7BywVbCZj8",
        "colab_type": "text"
      },
      "source": [
        "## Computing a Train, Validation, Test split in Sklearn\n",
        "\n",
        "Here the train is 60%, the validation is 20% and the test is 20% over the whole dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuan_WhZc6_f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        " X_train, X_test, y_train, y_test \n",
        "    = train_test_split(X, y, test_size=0.2, random_state=1)\n",
        "\n",
        " X_train, X_val, y_train, y_val \n",
        "    = train_test_split(X_train, y_train, test_size=0.25, random_state=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBSUmz1kfDQd",
        "colab_type": "text"
      },
      "source": [
        "## Computing a Train, Validation, Test split in Keras\n",
        "\n",
        "In Keras is slightly easier to compute a validation split, you just pass it to the *fit* function. \n",
        "\n",
        "If you set the validation_split argument in model.fit to e.g. 0.1, then the validation data used will be the last 10% of the data. If you set it to 0.25, it will be the last 25% of the data, etc. Note that the data isn't shuffled before extracting the validation split, so the validation is literally just the last x% of samples in the input you passed.\n",
        "\n",
        "The same validation set is used for all epochs (within a same call to fit)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LL-OPc9DgdAl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hist = model.fit(x_train, y_train, validation_split=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fi49BCiK2UWa",
        "colab_type": "text"
      },
      "source": [
        "## Your turn\n",
        "\n",
        "Perform a TVT split over the dataset chosen for your project. Print the shape of each subset. If you do not have a dataset yet, chose iris dataset from sklearn."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBOua6zl6V2n",
        "colab_type": "text"
      },
      "source": [
        "# Cross-validation again"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOY90MmahETl",
        "colab_type": "text"
      },
      "source": [
        "## Evaluating estimator performance\n",
        "\n",
        "Learning the parameters of a prediction function and testing it on the same data is a methodological mistake: `a model that would just repeat the labels of the samples that it has just seen would have a perfect score but would fail to predict anything useful on yet-unseen data`. This situation is called **overfitting**. To avoid it, it is common practice when performing a `(supervised) machine learning` experiment to hold out part of the available data as a test set `X_test, y_test`. \n",
        "\n",
        "Here is a flowchart of typical cross validation workflow in model training. The best parameters can be determined by `grid search` techniques.\n",
        "\n",
        "![alt text](https://scikit-learn.org/stable/_images/grid_search_workflow.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnacZjeR6YKw",
        "colab_type": "code",
        "outputId": "c95fcfef-2034-4830-97a7-fac9c29c145e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import datasets\n",
        "from sklearn import svm\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "iris.data.shape, iris.target.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((150, 4), (150,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcteGGrzjmsQ",
        "colab_type": "text"
      },
      "source": [
        "We can now quickly sample a training set while holding out 40% of the data for testing (evaluating) our classifier:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nr6RYD2MkJKY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, \\\n",
        "y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.4, random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTqa3W5XkR8C",
        "colab_type": "code",
        "outputId": "453710b3-f900-4ed6-bdd4-1de38ba9b9c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "X_train.shape, y_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((90, 4), (90,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2filw8IwkVfz",
        "colab_type": "code",
        "outputId": "ebfe9a22-e981-4cad-a253-ec0df424e67a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "X_test.shape, y_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60, 4), (60,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2keCxXKkaWB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PrSRumlkVnZ",
        "colab_type": "code",
        "outputId": "37c32a08-71b2-4f74-e06b-a28446222f7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "clf.score(X_test, y_test)                           "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9666666666666667"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rdXDtDkk2hf",
        "colab_type": "text"
      },
      "source": [
        "### The problem of under or overfitting: tuning model hyperparameters\n",
        "\n",
        "When evaluating different settings (“hyperparameters”) for estimators, such as the C setting that must be manually set for an SVM, there is still a **risk of overfitting on the test set** because the `parameters can be tweaked until the estimator performs optimally`. This way, `knowledge about the test set can “leak”` into the model and evaluation metrics no longer report on generalization performance. \n",
        "\n",
        "To solve this problem, `yet another part of the dataset can be held out as a so-called “validation set”`: training proceeds on the training set, after which evaluation is done on the validation set, and when the experiment seems to be successful, final evaluation can be done on the test set.\n",
        "\n",
        "However, by partitioning the available data into three sets, we drastically reduce the number of samples which can be used for learning the model, and the results can depend on a particular random choice for the pair of (train, validation) sets.\n",
        "\n",
        "A solution to this problem is a procedure called `cross-validation (CV for short)`. A test set should still be held out for final evaluation, but **the validation set is no longer needed** when doing CV. In the basic approach, called k-fold CV, the training set is split into k smaller sets. There are other approaches that we will learn later in the course.\n",
        "\n",
        "**Key takeaways**\n",
        "\n",
        "* When we train our algorithm, we get a score at the end.\n",
        "* We can modify the hyperparameters for our training in order to improve that score\n",
        "* That results in the fact that we are \"tuning\" the model based on the results on the test, thus leaking the test into the training and halting generalization\n",
        "* We could avoid this by using a validation set, to evaluate the model on training. However, this will reduce severly our dataset\n",
        "* We can use CV for maintaining the size of our dataset while using parts of it for evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyD-SNd0l3MB",
        "colab_type": "text"
      },
      "source": [
        "The following procedure is followed for each of the k “folds”:\n",
        "\n",
        "*  A model is trained using `k-1` of the folds as training data\n",
        "*  The resulting model is evaluated on the remaining part of the data (i.e., it is used as a test set to compute a performance measure such as accuracy).\n",
        "\n",
        "The performance measure reported by k-fold cross-validation is then the average of the values computed in the loop. **This approach can be computationally expensive**, but does not waste too much data (as is the case when fixing an arbitrary validation set), which is a major advantage in problems when our data is too small.\n",
        "\n",
        "![alt text](https://scikit-learn.org/stable/_images/grid_search_cross_validation.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-iWTWJooWzq",
        "colab_type": "text"
      },
      "source": [
        "### Computing cross-validation metrics\n",
        "\n",
        "The simplest way to use cross-validation is to call the `cross_val_score` helper function on the estimator and the dataset.\n",
        "\n",
        "The following example demonstrates how to estimate the accuracy of a linear kernel support vector machine on the iris dataset by splitting the data, fitting a model and computing the score 5 consecutive times (with different splits each time):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Jm9Jxx3k9q9",
        "colab_type": "code",
        "outputId": "7aada166-83c3-4a1e-cf86-67ed493f2373",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "clf = svm.SVC(kernel='linear', C=1)\n",
        "scores = cross_val_score(clf, iris.data, iris.target, cv=5)\n",
        "scores                                              "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.96666667, 1.        , 0.96666667, 0.96666667, 1.        ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoAH-Xugpxb4",
        "colab_type": "text"
      },
      "source": [
        "The mean score and the 95% confidence interval of the score estimate are hence given by:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5ZF3r3zpyzQ",
        "colab_type": "code",
        "outputId": "4f196c22-b3de-4641-b239-e8526e2e64dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.98 (+/- 0.03)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNUinRRDp8Bd",
        "colab_type": "text"
      },
      "source": [
        "By default, the score computed at each CV iteration is the score method of the estimator. It is possible to change this by using the scoring parameter.\n",
        "\n",
        "You can check the available scorings [here](https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-N5EoAd9py2D",
        "colab_type": "code",
        "outputId": "57ed9ae9-4ff1-4715-f5ec-25444439cf6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from sklearn import metrics\n",
        "scores = cross_val_score(clf, iris.data, iris.target, cv=5, scoring='f1_macro')\n",
        "scores  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.96658312, 1.        , 0.96658312, 0.96658312, 1.        ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V277nXfmrUO6",
        "colab_type": "text"
      },
      "source": [
        "#### Tweaking n_jobs\n",
        "\n",
        "Cross validation it is a heavy computing process, we can tweak the number of CPUs involved by using n_jobs (-1 uses all the available ones by default). Be careful, if your model is too big leave one CPU out so you can still watch videos on YouTube."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6dW7Egkpy6Y",
        "colab_type": "code",
        "outputId": "5f74a4de-2e66-4507-f544-429bc43f3417",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from sklearn import metrics\n",
        "scores = cross_val_score(clf, iris.data, iris.target, cv=5, scoring='f1_macro', n_jobs=-1)\n",
        "scores  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.96658312, 1.        , 0.96658312, 0.96658312, 1.        ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gymAY6yBsd_I",
        "colab_type": "text"
      },
      "source": [
        "In the case of the Iris dataset, the samples are balanced across target classes hence the accuracy and the F1-score are almost equal.\n",
        "\n",
        "When the `cv argument is an integer`, cross_val_score uses the `KFold` or StratifiedKFold strategies by default, the latter being used if the estimator derives from ClassifierMixin."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eO-rm4YXtxMB",
        "colab_type": "text"
      },
      "source": [
        "## Parameter estimation: GridSearch + Cross Validation\n",
        "\n",
        "We can use GridSearch + CrossValidation to select our model parameters.\n",
        "\n",
        "We use the dedicated function called GridSearchCV which can be used for that matter.\n",
        "\n",
        "The performance of the selected hyper-parameters and trained model is then measured on a dedicated evaluation set that was not used during the model selection step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lp-cwK38visl",
        "colab_type": "code",
        "outputId": "851e71f0-4642-47a3-94dd-62282d073cec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Loading the Digits dataset\n",
        "digits = datasets.load_digits()\n",
        "\n",
        "# To apply an classifier on this data, we need to flatten the image, to\n",
        "# turn the data in a (samples, feature) matrix:\n",
        "n_samples = len(digits.images)\n",
        "X = digits.images.reshape((n_samples, -1))\n",
        "y = digits.target\n",
        "\n",
        "print(X.shape, y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1797, 64) (1797,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTes7ovTvtAC",
        "colab_type": "code",
        "outputId": "246dbabf-67a4-437c-e378-795cdfc2e34f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "# Split the dataset in two equal parts\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.5, random_state=0)\n",
        "\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_test.shape, y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(898, 64) (898,)\n",
            "(899, 64) (899,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4DnDmZEpy9n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set the parameters by cross-validation\n",
        "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
        "                     'C': [1, 10, 100, 1000]},\n",
        "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbdaNswZxm6H",
        "colab_type": "code",
        "outputId": "cbd6c16b-b19b-4efd-b674-ba0125304284",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 755
        }
      },
      "source": [
        "import sklearn\n",
        "sorted(sklearn.metrics.SCORERS.keys())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['accuracy',\n",
              " 'adjusted_mutual_info_score',\n",
              " 'adjusted_rand_score',\n",
              " 'average_precision',\n",
              " 'balanced_accuracy',\n",
              " 'brier_score_loss',\n",
              " 'completeness_score',\n",
              " 'explained_variance',\n",
              " 'f1',\n",
              " 'f1_macro',\n",
              " 'f1_micro',\n",
              " 'f1_samples',\n",
              " 'f1_weighted',\n",
              " 'fowlkes_mallows_score',\n",
              " 'homogeneity_score',\n",
              " 'jaccard',\n",
              " 'jaccard_macro',\n",
              " 'jaccard_micro',\n",
              " 'jaccard_samples',\n",
              " 'jaccard_weighted',\n",
              " 'max_error',\n",
              " 'mutual_info_score',\n",
              " 'neg_log_loss',\n",
              " 'neg_mean_absolute_error',\n",
              " 'neg_mean_squared_error',\n",
              " 'neg_mean_squared_log_error',\n",
              " 'neg_median_absolute_error',\n",
              " 'normalized_mutual_info_score',\n",
              " 'precision',\n",
              " 'precision_macro',\n",
              " 'precision_micro',\n",
              " 'precision_samples',\n",
              " 'precision_weighted',\n",
              " 'r2',\n",
              " 'recall',\n",
              " 'recall_macro',\n",
              " 'recall_micro',\n",
              " 'recall_samples',\n",
              " 'recall_weighted',\n",
              " 'roc_auc',\n",
              " 'v_measure_score']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v73MMQYDwknh",
        "colab_type": "code",
        "outputId": "4b380479-49bf-4c3b-9325-9638dddbfe20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        }
      },
      "source": [
        "clf = GridSearchCV(SVC(), tuned_parameters, cv=5,\n",
        "                    scoring='accuracy')\n",
        "clf.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
              "             estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
              "                           decision_function_shape='ovr', degree=3,\n",
              "                           gamma='auto_deprecated', kernel='rbf', max_iter=-1,\n",
              "                           probability=False, random_state=None, shrinking=True,\n",
              "                           tol=0.001, verbose=False),\n",
              "             iid='warn', n_jobs=None,\n",
              "             param_grid=[{'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001],\n",
              "                          'kernel': ['rbf']},\n",
              "                         {'C': [1, 10, 100, 1000], 'kernel': ['linear']}],\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='accuracy', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGawqPJqx296",
        "colab_type": "code",
        "outputId": "8fd59d9b-73fb-4fa0-e0be-2633280b7672",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "clf.best_params_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSav15cByFC0",
        "colab_type": "text"
      },
      "source": [
        "### Using more than one metric"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8X5mkrFyI_R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set the parameters by cross-validation\n",
        "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
        "                     'C': [1, 10, 100, 1000]},\n",
        "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
        "\n",
        "scores = ['accuracy','precision', 'recall']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PShTcnNcwPm3",
        "colab_type": "code",
        "outputId": "02f3c081-37d7-4345-da89-4dc24fbf9ddc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for score in scores:\n",
        "    print(\"-----------------------------------------\")\n",
        "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
        "    print()\n",
        "\n",
        "    if score == 'accuracy':\n",
        "\n",
        "        clf = GridSearchCV(SVC(), tuned_parameters, cv=5,\n",
        "                        scoring=score)\n",
        "        clf.fit(X_train, y_train)\n",
        "\n",
        "    else:\n",
        "\n",
        "        clf = GridSearchCV(SVC(), tuned_parameters, cv=5,\n",
        "                        scoring='%s_macro' % score)\n",
        "        clf.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "    print(\"Best parameters set found on development set:\")\n",
        "    print()\n",
        "    print(clf.best_params_)\n",
        "    print()\n",
        "    print(\"Grid scores on development set:\")\n",
        "    print()\n",
        "    means = clf.cv_results_['mean_test_score']\n",
        "    stds = clf.cv_results_['std_test_score']\n",
        "\n",
        "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
        "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
        "              % (mean, std * 2, params))\n",
        "    print()\n",
        "\n",
        "    print(\"Detailed classification report:\")\n",
        "    print()\n",
        "    print(\"The model is trained on the full development set.\")\n",
        "    print(\"The scores are computed on the full evaluation set.\")\n",
        "    print()\n",
        "    y_true, y_pred = y_test, clf.predict(X_test)\n",
        "    print(classification_report(y_true, y_pred))\n",
        "    print()\n",
        "\n",
        "# Note the problem is too easy: the hyperparameter plateau is too flat and the\n",
        "# output model is the same for precision and recall with ties in quality."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-----------------------------------------\n",
            "# Tuning hyper-parameters for accuracy\n",
            "\n",
            "Best parameters set found on development set:\n",
            "\n",
            "{'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
            "\n",
            "Grid scores on development set:\n",
            "\n",
            "0.986 (+/-0.021) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
            "0.958 (+/-0.029) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
            "0.987 (+/-0.021) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
            "0.981 (+/-0.029) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
            "0.987 (+/-0.021) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
            "0.981 (+/-0.027) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
            "0.987 (+/-0.021) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
            "0.981 (+/-0.027) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
            "0.973 (+/-0.015) for {'C': 1, 'kernel': 'linear'}\n",
            "0.973 (+/-0.015) for {'C': 10, 'kernel': 'linear'}\n",
            "0.973 (+/-0.015) for {'C': 100, 'kernel': 'linear'}\n",
            "0.973 (+/-0.015) for {'C': 1000, 'kernel': 'linear'}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "The model is trained on the full development set.\n",
            "The scores are computed on the full evaluation set.\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        89\n",
            "           1       0.97      1.00      0.98        90\n",
            "           2       0.99      0.98      0.98        92\n",
            "           3       1.00      0.99      0.99        93\n",
            "           4       1.00      1.00      1.00        76\n",
            "           5       0.99      0.98      0.99       108\n",
            "           6       0.99      1.00      0.99        89\n",
            "           7       0.99      1.00      0.99        78\n",
            "           8       1.00      0.98      0.99        92\n",
            "           9       0.99      0.99      0.99        92\n",
            "\n",
            "    accuracy                           0.99       899\n",
            "   macro avg       0.99      0.99      0.99       899\n",
            "weighted avg       0.99      0.99      0.99       899\n",
            "\n",
            "\n",
            "-----------------------------------------\n",
            "# Tuning hyper-parameters for precision\n",
            "\n",
            "Best parameters set found on development set:\n",
            "\n",
            "{'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
            "\n",
            "Grid scores on development set:\n",
            "\n",
            "0.986 (+/-0.016) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
            "0.959 (+/-0.029) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
            "0.988 (+/-0.017) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
            "0.982 (+/-0.026) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
            "0.988 (+/-0.017) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
            "0.982 (+/-0.025) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
            "0.988 (+/-0.017) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
            "0.982 (+/-0.025) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
            "0.975 (+/-0.014) for {'C': 1, 'kernel': 'linear'}\n",
            "0.975 (+/-0.014) for {'C': 10, 'kernel': 'linear'}\n",
            "0.975 (+/-0.014) for {'C': 100, 'kernel': 'linear'}\n",
            "0.975 (+/-0.014) for {'C': 1000, 'kernel': 'linear'}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "The model is trained on the full development set.\n",
            "The scores are computed on the full evaluation set.\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        89\n",
            "           1       0.97      1.00      0.98        90\n",
            "           2       0.99      0.98      0.98        92\n",
            "           3       1.00      0.99      0.99        93\n",
            "           4       1.00      1.00      1.00        76\n",
            "           5       0.99      0.98      0.99       108\n",
            "           6       0.99      1.00      0.99        89\n",
            "           7       0.99      1.00      0.99        78\n",
            "           8       1.00      0.98      0.99        92\n",
            "           9       0.99      0.99      0.99        92\n",
            "\n",
            "    accuracy                           0.99       899\n",
            "   macro avg       0.99      0.99      0.99       899\n",
            "weighted avg       0.99      0.99      0.99       899\n",
            "\n",
            "\n",
            "-----------------------------------------\n",
            "# Tuning hyper-parameters for recall\n",
            "\n",
            "Best parameters set found on development set:\n",
            "\n",
            "{'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
            "\n",
            "Grid scores on development set:\n",
            "\n",
            "0.986 (+/-0.019) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
            "0.957 (+/-0.029) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
            "0.987 (+/-0.019) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
            "0.981 (+/-0.028) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
            "0.987 (+/-0.019) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
            "0.981 (+/-0.026) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
            "0.987 (+/-0.019) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
            "0.981 (+/-0.026) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
            "0.972 (+/-0.012) for {'C': 1, 'kernel': 'linear'}\n",
            "0.972 (+/-0.012) for {'C': 10, 'kernel': 'linear'}\n",
            "0.972 (+/-0.012) for {'C': 100, 'kernel': 'linear'}\n",
            "0.972 (+/-0.012) for {'C': 1000, 'kernel': 'linear'}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "The model is trained on the full development set.\n",
            "The scores are computed on the full evaluation set.\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        89\n",
            "           1       0.97      1.00      0.98        90\n",
            "           2       0.99      0.98      0.98        92\n",
            "           3       1.00      0.99      0.99        93\n",
            "           4       1.00      1.00      1.00        76\n",
            "           5       0.99      0.98      0.99       108\n",
            "           6       0.99      1.00      0.99        89\n",
            "           7       0.99      1.00      0.99        78\n",
            "           8       1.00      0.98      0.99        92\n",
            "           9       0.99      0.99      0.99        92\n",
            "\n",
            "    accuracy                           0.99       899\n",
            "   macro avg       0.99      0.99      0.99       899\n",
            "weighted avg       0.99      0.99      0.99       899\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWzGricM2kH2",
        "colab_type": "text"
      },
      "source": [
        "## Your turn\n",
        "\n",
        "Estimate the best parameters for your training, taking into account accuracy alone, for your dataset using Cross Validation.\n",
        "\n",
        "If you are doing a classification problem, try precision and recall as well."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXjDs4jPGjKe",
        "colab_type": "text"
      },
      "source": [
        "# Predicting probabilities: PR and ROC curves\n",
        "\n",
        "When making a prediction for a binary or two-class classification problem, there are two types of errors that we could make.\n",
        "\n",
        "* **False Positive**. Predict an event when there was no event.\n",
        "* **False Negative**. Predict no event when in fact there was an event.\n",
        "\n",
        "By predicting probabilities and calibrating a threshold, a balance of these two concerns can be chosen by the operator of the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPfv1Vr-8ETx",
        "colab_type": "text"
      },
      "source": [
        "**Precision** ($P$) is defined as the number of true positives ($T_p$) over the number of true positives plus the number of false positives ($F_p$).\n",
        "\n",
        "$P = \\frac{T_p}{T_p+F_p}$\n",
        "\n",
        "**Recall or Sensitivity** ($R$) is defined as the number of true positives ($T_p$) over the number of true positives plus the number of false negatives ($F_n$).\n",
        "\n",
        "$R = \\frac{T_p}{T_p + F_n}$\n",
        "\n",
        "These quantities are also related to the ($F_1$) score, which is defined as the **harmonic mean of precision and recall**.\n",
        "\n",
        "$F1 = 2\\frac{P \\times R}{P+R}$\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwIO6J_tHUZr",
        "colab_type": "text"
      },
      "source": [
        "## ROC curves\n",
        "\n",
        "A useful tool to predict probability of binary outcume (only binary!) is the Receiver Operating Characteristic cruve or ROC curve.\n",
        "\n",
        "The ROC curve plots the **FALSE POSITIVE RATE** (x-axis) versus the **TRUE POSITIVE RATE** (y-axis). We know that the **TRUE POSITIVE RATE** is the Recall or Sensitivity, but what is the **FALSE POSITIVE RATE**?\n",
        "\n",
        "$FPR = \\frac{F_p}{F_p+T_n}$\n",
        "\n",
        "It is a plot of the false positive rate (x-axis) versus the true positive rate (y-axis) for a number of different candidate threshold values between 0.0 and 1.0. Put another way, it plots the false alarm rate versus the hit rate.\n",
        "\n",
        "* Smaller values on the x-axis of the plot indicate lower false positives and higher true negatives.\n",
        "* Larger values on the y-axis of the plot indicate higher true positives and lower false negatives.\n",
        "\n",
        "`If you are confused, remember, when we predict a binary outcome, it is either a correct prediction (true positive) or not (false positive). There is a tension between these options, the same with true negative and false negative.`\n",
        "\n",
        "A skilful model will assign a higher probability to a randomly chosen real positive occurrence than a negative occurrence on average. This is what we mean when we say that the model has skill. Generally, skilful models are represented by curves that bow up to the top left of the plot.\n",
        "\n",
        "A no-skill classifier is one that cannot discriminate between the classes and would predict a random class or a constant class in all cases. A model with no skill is represented at the point (0.5, 0.5). A model with no skill at each threshold is represented by a diagonal line from the bottom left of the plot to the top right and has an AUC of 0.5.\n",
        "\n",
        "A model with perfect skill is represented at a point (0,1). A model with perfect skill is represented by a line that travels from the bottom left of the plot to the top left and then across the top to the top right.\n",
        "\n",
        "An operator may plot the ROC curve for the final model and choose a threshold that gives a desirable balance between the false positives and false negatives.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kw5v8V38Kplh",
        "colab_type": "code",
        "outputId": "af4dbbab-4095-4c06-b677-64f3fb48339c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        }
      },
      "source": [
        "# roc curve and auc\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from matplotlib import pyplot\n",
        "\n",
        "# generate 2 class dataset\n",
        "X, y = make_classification(n_samples=1000, n_classes=2, random_state=1)\n",
        "\n",
        "# split into train/test sets\n",
        "trainX, testX, trainy, testy = train_test_split(X, y, test_size=0.5, random_state=2)\n",
        "\n",
        "# generate a no skill prediction (majority class)\n",
        "ns_probs = [0 for _ in range(len(testy))]\n",
        "\n",
        "# fit a model\n",
        "model = LogisticRegression(solver='lbfgs')\n",
        "model.fit(trainX, trainy)\n",
        "\n",
        "# predict probabilities\n",
        "lr_probs = model.predict_proba(testX)\n",
        "\n",
        "# keep probabilities for the positive outcome only\n",
        "lr_probs = lr_probs[:, 1]\n",
        "\n",
        "# calculate scores\n",
        "ns_auc = roc_auc_score(testy, ns_probs)\n",
        "lr_auc = roc_auc_score(testy, lr_probs)\n",
        "\n",
        "# summarize scores\n",
        "print('No Skill: ROC AUC=%.3f' % (ns_auc))\n",
        "print('Logistic: ROC AUC=%.3f' % (lr_auc))\n",
        "\n",
        "# calculate roc curves\n",
        "#No skill model\n",
        "ns_fpr, ns_tpr, thres_ns = roc_curve(testy, ns_probs)\n",
        "# Logarithmic model\n",
        "lr_fpr, lr_tpr, thres_lr = roc_curve(testy, lr_probs)\n",
        "\n",
        "# plot the roc curve for the model\n",
        "pyplot.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
        "pyplot.plot(lr_fpr, lr_tpr, marker='.', label='Logistic')\n",
        "\n",
        "# axis labels\n",
        "pyplot.xlabel('False Positive Rate')\n",
        "pyplot.ylabel('True Positive Rate')\n",
        "\n",
        "# show the legend\n",
        "pyplot.legend()\n",
        "# show the plot\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No Skill: ROC AUC=0.500\n",
            "Logistic: ROC AUC=0.903\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmiBH5szPjVI",
        "colab_type": "code",
        "outputId": "0f3b6363-f992-42b1-8982-38ba06778330",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        }
      },
      "source": [
        "thres_lr"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.99981055e+00, 9.99810555e-01, 9.92408365e-01, 9.91679828e-01,\n",
              "       9.90144555e-01, 9.89867568e-01, 9.79265264e-01, 9.79115074e-01,\n",
              "       9.61958719e-01, 9.61681033e-01, 9.47453942e-01, 9.46083338e-01,\n",
              "       9.24765054e-01, 9.23985965e-01, 9.03776284e-01, 8.96563782e-01,\n",
              "       8.88294853e-01, 8.87112806e-01, 8.78078335e-01, 8.76612424e-01,\n",
              "       8.28429524e-01, 8.27959147e-01, 8.23317999e-01, 8.22322697e-01,\n",
              "       8.07658186e-01, 8.07653554e-01, 7.79441385e-01, 7.68060225e-01,\n",
              "       7.63062006e-01, 7.62912313e-01, 7.61564252e-01, 7.58648634e-01,\n",
              "       7.49642618e-01, 7.46446600e-01, 7.32873897e-01, 7.31335000e-01,\n",
              "       7.23434675e-01, 7.15862908e-01, 6.92545325e-01, 6.92512778e-01,\n",
              "       6.92244651e-01, 6.82799726e-01, 6.80222962e-01, 6.79729854e-01,\n",
              "       6.70153267e-01, 6.56639891e-01, 6.47658558e-01, 6.46419471e-01,\n",
              "       6.36044813e-01, 6.35647643e-01, 6.18886716e-01, 6.14825818e-01,\n",
              "       6.12198494e-01, 6.03026960e-01, 5.92619457e-01, 5.90439114e-01,\n",
              "       5.73275256e-01, 5.70823475e-01, 5.70540796e-01, 5.69625194e-01,\n",
              "       5.61264294e-01, 5.60434187e-01, 5.50598070e-01, 5.32524455e-01,\n",
              "       5.29530623e-01, 5.27652986e-01, 5.13088042e-01, 5.01616608e-01,\n",
              "       4.89796043e-01, 4.67589167e-01, 4.64207032e-01, 4.55753661e-01,\n",
              "       4.53820020e-01, 4.50593094e-01, 4.39643321e-01, 4.34572049e-01,\n",
              "       4.33772072e-01, 3.98840087e-01, 3.74613530e-01, 3.55286739e-01,\n",
              "       3.42917946e-01, 3.40707625e-01, 3.31011154e-01, 3.17835539e-01,\n",
              "       3.10549670e-01, 3.06873780e-01, 3.02319728e-01, 2.97576317e-01,\n",
              "       2.96743999e-01, 2.88726892e-01, 2.88427796e-01, 2.82301704e-01,\n",
              "       2.79559594e-01, 2.79345925e-01, 2.75234284e-01, 2.51809563e-01,\n",
              "       2.29544010e-01, 2.23874663e-01, 2.09170025e-01, 1.98691303e-01,\n",
              "       1.84443372e-01, 1.22859592e-01, 1.14683308e-01, 9.83635286e-02,\n",
              "       9.31224664e-02, 8.83659795e-02, 8.55737954e-02, 8.33877256e-02,\n",
              "       8.28245628e-02, 7.81879280e-02, 7.29965896e-02, 5.45950280e-02,\n",
              "       5.32689607e-02, 4.89366919e-02, 4.75728835e-02, 2.25464897e-02,\n",
              "       2.21934800e-02, 1.77269799e-02, 1.68725428e-02, 6.23690579e-03,\n",
              "       6.13750462e-03, 8.11560718e-05])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIeoxopFSh5I",
        "colab_type": "text"
      },
      "source": [
        "### Finding the best threshold: cutoff point\n",
        "\n",
        "This depends on our classification problem!!!! If we are dealing with crimes (when people are dead) we want to maximize, TPR so that we avoid people dying. But in a non life threatening scenario, we can actually use this method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KWoIbY0T-Yg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "def Find_Optimal_Cutoff(target, predicted):\n",
        "    \"\"\" Find the optimal probability cutoff point for a classification model related to event rate\n",
        "    Parameters\n",
        "    ----------\n",
        "    target : Matrix with dependent or target data, where rows are observations\n",
        "\n",
        "    predicted : Matrix with predicted data, where rows are observations\n",
        "\n",
        "    Returns\n",
        "    -------     \n",
        "    list type, with optimal cutoff value\n",
        "\n",
        "    \"\"\"\n",
        "    fpr, tpr, threshold = roc_curve(target, predicted)\n",
        "    i = np.arange(len(tpr)) \n",
        "    roc = pd.DataFrame({'tf' : pd.Series(tpr-(1-fpr), index=i), \n",
        "                        'threshold' : pd.Series(threshold, index=i),\n",
        "                        'tpr': pd.Series(tpr, index=i),\n",
        "                        'fpr': pd.Series((fpr), index=i)})\n",
        "    \n",
        "    roc_t = roc.iloc[(roc.tf-0).abs().argsort()[:1]]\n",
        "\n",
        "    return list(roc_t['threshold']), list(roc_t['tpr']), list(roc_t['fpr'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDdgimkAKprQ",
        "colab_type": "code",
        "outputId": "9430c86a-aa9c-497d-92eb-48c0da3d2d6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        }
      },
      "source": [
        "####################################\n",
        "# The optimal cut off would be where tpr is high and fpr is low\n",
        "# tpr - (1-fpr) is zero or near to zero is the optimal cut off point\n",
        "####################################\n",
        "\n",
        "a, b, c = Find_Optimal_Cutoff(testy, lr_probs)\n",
        "\n",
        "print(\"Best threshold\", a)\n",
        "print(\"Best TPR\", b)\n",
        "print(\"Best FPR\", c)\n",
        "\n",
        "# plot the roc curve for the model\n",
        "pyplot.plot(1-lr_fpr, linestyle='--', label='1-FPR')\n",
        "pyplot.plot(lr_tpr, marker='.', label='TPR')\n",
        "\n",
        "# axis labels\n",
        "pyplot.xlabel('False Positive Rate')\n",
        "pyplot.ylabel('True Positive Rate')\n",
        "\n",
        "# show the legend\n",
        "pyplot.legend()\n",
        "# show the plot\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best threshold [0.529530623434401]\n",
            "Best TPR [0.8346153846153846]\n",
            "Best FPR [0.16666666666666666]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deXxU9dX48c+ZyUo21iRAggQB2QmK\nuOKuRUXoohWt1rUWn9pW69NWa6vWPv21tmrr1lpbFbXWtaKIu4iKgkZQ9l0IJBhICBC2rJPz++Pe\nhEnIMoHMljnv1yuvmblzZ+ZcB++Z+13OV1QVY4wxscsT7gCMMcaElyUCY4yJcZYIjDEmxlkiMMaY\nGGeJwBhjYlxcuAPoqN69e+vAgQPDHYYxxkSVRYsWbVfVPi09F3WJYODAgSxcuDDcYRhjTFQRkU2t\nPWdNQ8YYE+MsERhjTIyzRGCMMTHOEoExxsQ4SwTGGBPjgpYIRORxESkVkeWtPC8i8oCIrBeRpSJy\ndLBiMcYY07pgDh+dATwEPNXK8+cCQ9y/44C/u7fGGGMAigqgcB4MnOg8brifO6FTPyZoiUBVPxKR\ngW3sMhV4Sp062J+KSHcR6auqJcGKaeaXxWws29dkW2pSHNeePAiPR4L1scYY077mJ/1FT8DSF6De\nB9LQeKPgTYQrZnVqMgjnhLL+QJHf42J320GJQESuA64DGDBgwCF/4GtLSpi7prTJtjH9M7julCMB\n+OVLS9m5v4aUxDhOO6oPZwzLJC0p/pA/zxhjWuR/0q+rho//ChveB60HGn6U+q0Vo74D9301zmu7\nSCIImKo+CjwKMH78+ENeSefxK489aFtNXX3j/a8rKinbU832vTXM/HILCV4PPztnKNNPPRJfvXL/\nnHWcOSyToVlpiIDXI8R7rb/dGONqqSlHvLCzEPqOhdpKWPxv2LaSJif6JppvF/DGO7f1deBNOPD+\nnSSciWALkOv3OMfdFlIJcQdO5E9f43RR1NcrX2zeyVvLt9KvezIA60r38Le563lgzrrG/eM8wn0X\n5zNlbD/K91ZTtLOSlAQvQ7LSQnsQxpjQO6gpZwYsfb5pU47/L/mANDvpe7ww7jIYe4nzdLT1EQRg\nFnCDiDyH00lcEcz+gY7weITxA3syfmDPxm3DstNZ9OuzmbN6G9t2VwOwY181+TndAZizqpRf/Hcp\nAOeOyuauqaPok5YY+uCNMZ2v4aSf3Av2boN922HhY+6Jvp2mnEbSdJ9DOel3cgJojCRYaxaLyLPA\naUBvYBtwBxAPoKqPiIjgjCqaBOwHrlLVdqvJjR8/XiOx6NzXuypZs3UPy7ZU8NDc9XRL8HLzOUdx\n+fFHALCqZDeDM1OtKcmYSOJ/gq8sd068lTth/RxIyoC9W2FXMWyYS+tNOc01nOABXx1Q71wheOII\n9S/9JlGJLFLV8S0+F22L10dqIvC3vnQvv3llOX0zkrjv4nz219RxzO/eIzHew7DsNAQhKd7D9FOP\n5LhBvcIdrjGxoflJPz4Z3r3D6XztMHFO5qrObVsneP8k07AtyCf9FiNuIxFERWdxtBmcmcqz1x3f\n+DjO4+H+afm8tXwrxTsrAWX11j1s2VUJwO6qWqpqfSR6vWR0s1FKxhy2NptyOsoDHg/U19P4696b\nCJP+2P4JvqWTfYgTQCAsEYRAQpyHc0Zmc87I7MZtVbU+Et2O6j+8sZpnCzYD8N3xOdx2/ggyki0h\nGBOQ9e/BV3OdppyKYthVFHhTjri/6ps33/hqafGk7//rvvkJPQJP8IGyRBAmSfHexvtT8/sxsl86\nG8r28eSCQj5cW8b908ZxvNtsVFXra7K/MTHL/5f+vlLY8iWsfSOAF7pNOa39qm+p+aatk34XY4kg\nAhw/qFfjSf9b4/rzi/8uZXHRLo4f1ItFm3Yy/d+LuPOCkZw3Ohunj92YGLRpPjx5gdMW36Z2mnIC\nOcF38RN/c5YIIszonAze+MnJ1PiciW5pSXFkpyfxo/98wZDMVBLjPcR7PTz7g+PtKsF0bf6//veU\nwJdPt5AEOvBLP8ZO7h1hiSACiQiJcc5JfmhWGjP/50RmzC9kwVflAOT0SG5MAhc8+DGrt+7GI8Kx\nA3ty7uhszhiWSd8MZyKcqtpVhIk+RQUwYzL4qptu98TZST8ILBFEgTivh2snDuLaiYMOeu47R/en\ndE9v9tf4+HBtGbfNXM7F43O5+8Ix1PrqOff+eRyX15PjBvUiziN4BPJze5CdkRSGIzEmQAX/PDgJ\niAeOvhwycu2k38ksEUS5K0/Ka7yvqqzZtoeqWqdZqaKylqOy05j55Rae+Wxz436/mTyCa07OY33p\nXmYt+RoBxuZmcNLg3o1XIsaElH8zUOkKWDETRECFJr/+x15qJ/4gsETQhYgIw7LTGx/3Tk3k4UuP\npqrWx6by/QBU1/nI7dENgI3b9zWpnZSWGMexeT2556Kx9ExJYHP5furq6xnUJzW0B2K6tuYTuxLT\n4e1fuUM2G4Z8Cpx9F9TX2q//ELBEEAOS4r0clX1wIbyzR2RR+Mfzqa7zMX99OW8uL2FpcQV19c4V\nxT8++opnPttMv4ykxuJ8I/tl8JeL80mI81BV60zOSYzzWD+EaZn/SX//dqjeAwsean/kj4iTBCbe\nHJo4Y5wlAkNinJfTh2Vy+rDMJttvOGMwgzNTWVK0CwXqfEpVra8xKVz4yHyWb9lNXu8Uzh2VzSlD\n+9AvI5kBvbqF4ShMSLVUo6feB4UfQ7eesH0dVBTBmjfcGvvtEK+7nx5oBurkUsumdVZryByyFxcW\nsW13FZ9t3MH8r8rx1SsXHpPDPReNxVev3PT8Yo4e0J3kBKffYXBmGuNyu9tqcNHmoKacDLcppwan\nKaeF6putsuGe4WK1hkxQXDTeWU7iBmDnvhqWFO8iK90ZjVRSUckXm3cya8nXTV7z6/OHc+3EQazd\ntodnCzZz9ogsTjyyd6hDN4Fa9x48e3E7TTmtJYBOmNhlQsISgekUPVISOO2oA01LOT26Me8Xp7Nt\ndzX1qvjqlUWbdjJ+YA8ASiqqeLZgM08v2MRDl45j0qi+4Qrd+Gv49Z/Uw1k6ce3bLScB/6YcPOA9\njBo9JuysaciEze6qWq58vIAlxRXcc9EYzh/dr8mKcSaIigpg+cvQZzigsP4dKN8AZaua7SjuJC4f\nVqMnulnTkIlI6UnxPHXNcVz9xOfc9PwS+mYkc/ygXny2oZwXFhZz5vBM0pKcf6Ij+qbTK9VWfOsU\nRQXwxLkB1OzBncR1WeCTuOzEH5UsEZiwSk2MY8bVx/LGsq3k9U4BYPOO/byzciv//aK4cb8+aYm8\nfeMp9ExJCFeoXcfCx/2SgP/yiS216SfYJK4YYInAhF23hDguPCan8fFF43OZmt+flSW7qfPVs6eq\njrXb9lgSCETzBdUL50FSdyhfD33HQtUuWPYiIG79fb/VtbwJ1qYfoywRmIiUEOchP7d74+OGOQ6f\nbSjnd6+vRBByeiQzaZRTZC8tyRbyoajAKdNcV+2c5EVab/7xJoR8zVwTuSwRmKihqry+rITMtCRU\nnVFIby7fSm7PZOb94gwA/vTWanyqnDMiix7dnCuIXqmJXXPFN/9f//X1MPtGqKtynlNfC6M6/ZqB\n6n2QkXPgxG8JIKZZIjBRQ0S4a+qoxsf19coXm3eytLiicVvRzkreXFbCPz7c0Ljt+EE9ee66E6jz\n1fPOym0AZKUnMi63R2RObmuxeacH7NwI/Y+GeoVFT8Cmj1uZtdswnBPw1XHQMowNzUA2c9e4bPio\n6XIq9teyYMN2quvqUXXWbxg/sCeVNT6G3/5W43590hI5e0QWl04YwKj+GdT66tmxr6ZxUlxYdKR5\np0UeOPI0OO1W52Hz4ZwN26wZKObY8FETUzK6xbc4QS0xzsPbN56Coqzdtpc3l5Uw84st5Od2Z1T/\nDBZ8Vc73Hy9g3IDuZKY5Q1V7pSZy/alHktszRPWTCucF3rzT8NgbT5Nf+qfd2naTjyUA04wlAhMz\nPB5prMI6LDudKWP7NXn+yMxUbj57KO+vKW0s2z1/fTk/On0wAI98+BXPFWymR0oC54zIZtKobPpm\nJHXukqHSMKGu4QRP6807Hq91+JpOYU1DxrShpq6+cbbzq4u38P7qUgq372OJ2y/RLyOJ+beeCcAL\nnxeRmhRH/+7OMqG9UhPI6dHOlYR/f0DVbnjxCqc+//irYdCpzj7WvGM6gTUNGXOI/EteTM3vz9T8\n/gBs2VXJ+6tLwf0hpao89vFG1mzb07i/R+Dmc45qvKI4qBN44ROw7AVnBI+I+17q1OsZdKo175iQ\nsURgzCHo3z2Zy48/wnlQVIAUzuP1b5/Eum2JJBR/Qk1Cd4o3byS5Zj+sK6Ri7v2kff0xgjPKR5q3\n9ftfmdfXOQnDTvYmRCwRGHM4Gkf51BDn8TAcGkf5DAcofQIWQAYHKvc7qUA5MHC1hQ5fG9ppQsgS\ngTEdcdAkrp8eGOVT3/ZKXM41gFCLFxTipB6vNw7GXcYrOpGhmekM2PMFtbknEtdnHAcvLmpMcFgi\nMKY1RQWw8SM44iRnNa5PHnBq9Gs9B6/K5ZZrhqYlm5uN8pFxl8HI7zJ7aQmD9y1m7MTJ7OqVzy//\n3xyq66qBkUAFIu9wy6Rh/PDUI6nYX8uyLRVkpScyJMvSg+l8lgiMaUm7pZr9R9t1bBJXIvCdPIBv\nA9AdWPSbs/lobRnl+2oAKN1d1biIz+qtu7nssc8AeOba4zhpsK3oZjpXUIePisgk4H7AC/xLVf/Y\n7PkBwJM4/y94gVtU9Y223tOGj5qQePUG+PLpVp5soU3/illB69zdXVXL6pI9/PylJXg9wps/nUhi\nXCfOXTAxoa3ho0FbDkpEvMDDwLnACOASERnRbLdfAy+o6jhgGvC3YMVjTMCq98K6d3FKNXudE703\n8cD98VfBla/DlbPhjNuCmgTAWcBnQl5PfjtlJBvK9vHPjza0/yJjOiCYTUMTgPWqugFARJ4DpgIr\n/fZRIN29nwE0XencmFDZOA9WvOLU7F/zOuzdCif+BJK7tz2JK4RDPE87KpPzRmczb912/ue0wZTv\nq6Guvp6+Gckhi8F0TcFMBP2BIr/HxcBxzfa5E3hHRH4MpABntfRGInIdcB3AgAEDOj1QE+NWvgYv\nXM5BNXwK/tn0134EjOu/+ztj6JYQh8cj3PfuGp4tKGJoViqTRvVlWHYa6UnxnDzE+hBMx4S7s/gS\nYIaq3isiJwBPi8go1aa1dVX1UeBRcPoIwhCn6Ur8h4DuLIRXf0ST0T80zPCtibiJXf4L8Hx3fC6D\nM9N4Z8VWHnx/HaowLDuNt248BXD6FtJtwR4TgGAmgi1Art/jHHebv2uASQCqukBEkoDeQGkQ4zKx\nrPATZwKY+g5+Lspq9o8b0INxA3pwzcl5lO+tpmxvdWMn8pqte7jw7/M5/sheeEXokZLALycdRfdu\nttynOVgwE8HnwBARycNJANOAS5vtsxk4E5ghIsOBJKAsiDGZWOP/679mP7x4ZctJAA8MOq3pENAo\nKurWKzWRXqmJjY97pMRz1ogsVn69G4B3V20DlD98e0yYIjSRLGiJQFXrROQG4G2coaGPq+oKEbkL\nWKiqs4CbgX+KyE041+NXarSVQzWRq6gAZpzvNPHgobHJB1r+9d9eHf8okpmWxF8uzm98/Ic3V1Hn\nU1QVkQhclc2ElZWhNl1Xq3MBWpgAFkW//g+FJQBjZahNbPBvBqoohqXP48wF8DiLuHTRX/+BaEgC\nn24o56kFhWSnJ5OWFMe1E/OadECb2GSJwHQNBzUDuQPPvPEw7nJbxcs184stzFu7HYC9NXWs3baH\nv33vaLtaiHGWCEx08v/1rwozf+gmAWhMAuBUBM3Iialf/225+8Ix3H2h02H86Edf8f/eWM3bK7a2\nuMaziR2WCEz08VsDAI/HqQbaMPUkyoaAhtMPJg6if/dunDMim+17q1ldsod4rzA2t3vnrsNsIp4l\nAhN9Vr3WyhoA0T0ENNREhPPHOFcCCwt3Mv3fiwDoluDl9GGZ5Od059LjBpCSaKeJrs6+YRP5GpqB\nknvBnhJY9qKzvUknsC8mO4E7y3F5PXlx+gnsqarlvVWlvL18K68vLWFKfj9SEuNs1FEXZ8NHTWRr\nbAaqpkktoOOmQ2pm2wXhzCHz1Sv7aupITYjjD2+uYs22vTx1tf23jWY2fNREr3XvHmgGaiROEph4\n84FNlgA6ldcjjXWKUhLjmLeujG27q8hKTwpzZCYYgrYegTGdomSJe6ehWcIDcUnWARxCk8f0QxVe\nX1oS7lBMkAR0RSAiCcAAVV0f5HhMrPPvDyj6DNa9DWOmQZ+hTZd/tCuAkBmcmcqw7DReX1bC1Sfn\nhTscEwTtJgIROR+4D0gA8kQkH7hDVb8V7OBMjNn8GTw52W8+AIDAuMsgz64AwmnymL7c885avt5V\nSb/uthBOVxPIFcFdOAvKzAVQ1cUiMjioUZnY4P/rv2w1rJjZLAkAIlBcYIkgzKaM7U91XT1xXqG6\nzodHhHivtSx3FYEkglpV3dVs6Fh0DTUy4ed/0q8sh/07YMHDHPRPyRPnzg2od4aHehOtPyACDOjV\njZvPOQqAU/88l03l+znmiB6cOyqbY47oQWZ6Ev3tSiFqBZIIVonIdwGPu7bAT4BPgxuW6VKa1AFq\ng3jh6MshI9f6AyLYDyYOoqSikrmry/i/11cBcPVJedx+wQhq6uq5/dXljM3tjlcEr0c4a3gWGd2s\nsF0kCyQR3ADcjlPA5WWc9QV+FcygTBfz1fstJ4GDfv0nwNhL7cQf4S47/ggAfv6NYRRu38dXZXvJ\n7dkNgA3b9/LGshKe+/zAcuV90hL55/fHk5/bPSzxmvYFkgi+oaq/BH7ZsEFEvo2TFIxpX2MZCHc9\n4IYmn0l/dH7126//qDWwdwoDe6c0Ph6Wnc6i35xN6Z5qALZWVPLAnPUM7OUkirvfWs3yLRWMG9CD\n80Znc1RWms1YjgDtziwWkS9U9ehm2xap6jFBjawVNrM4Cj01FUpXw4TroJud9GPZ/81eyacby1n5\n9W7qFbp3i+e0oX3467RxAHy8bjuDM1OJ80rjWsumcxzSzGIR+QbOwvL9ReQ+v6fSaVLn15g2VGyB\nDR/Cqb+EU25uf3/Tpf168ggAyvZU8/aKrawq2c1R2WkAVOyv5aoZBdT6Dvw4/eGpg7j13OFhiTWW\ntNU0VAosB6qAFX7b9wC3BDMo04UsewFQGHtxuCMxEaRPWmJjX0ODtKQ4XvjhCSz/ejeoUlC4k398\nuIGpY/szol96mCKNDYE0DSWpavNiL2FjTUNRoHGoaE+Y+3tIyYT/mR/uqEyUqamrZ8GGck4d2ifc\noXQJh1t0rr+I/B4YATRWnFLVoZ0Un4lm/vMD9m+H6t3O/ID6ugP7VO5y9rM+AdMBCXGexiTw29dW\nsGjTTgQ4b3Rfrjk5jzib0NZpAkkEM4D/A+4BzgWuwiaUGYCN8+CpKQdWB2uN1jvJwhKBOUTpSfH0\nSklgV2Utf3hzNbOXlvDXafkc2SeVqlofcR6xxHAYAvkv101V3wZQ1a9U9dc4CcHEMlV465YWkoC4\nS0W6/7Qa5gfY7GBzGG46eyhPXDWBl68/kYcvPZqvd1WyfEsFAIuLdjH5wY9ZVlwR5iijVyBXBNUi\n4gG+EpHpwBYgLbhhmYjk3wy08hXYtrzlkhA2P8AEScPymice2YvKWh8AvVMT2LGvhm/+7RMuPjaX\nzLREeqce3BltWhdIIrgJSMEpLfF7IAO4OphBmQi0cZ4zH0B9B7aJF867Byp32EnfhFSPlAR6uPcH\nZ6bx7k2n8vs3VvJcwWbqFYb3TbdE0AGHtFSliPRX1S1BiKddNmooDFThkZOdKwB/4oUzbmu6Upgx\nYeR/PrMZy00d8qghETkW6A98rKrbRWQkTqmJM4CcTo/URA7/ZqBVr7bSDGRt/yayNJz8V2/dzfz1\n5Vx10kBLCAFoa2bxH4DvAEuAX4vIbOB/gLuB6aEJz4SE/0l/xwbYXeysDeDfEWzNQCaKzF9fzl2z\nVzIlvx+9UxPDHU7Ea+uKYCowVlUrRaQnUASMVtUNoQnNBEXzcf/b18HS5wJ7beUOawYyUWFQH6cQ\n3oayfZYIAtBWIqhS1UoAVd0hImstCUS5zZ856wLU17azowc8HmsGMlHryD6pAGwo28uEvJ5hjiby\ntZUIBolIQ6lpwVmvuLH0tKp+u703F5FJwP2AF/iXqv6xhX2+C9yJM0ltiapeGnj4pkOWPt9CEhDw\neG0IqOlS+nVPJiHOw4bt+8IdSlRoKxF8p9njhzryxiLiBR4GzgaKgc9FZJaqrvTbZwhwK3CSqu4U\nkcyOfIbpoF2b3Tse7KRvujKvRxjUO4UNZXvDHUpUaDURqOqcw3zvCcD6huYkEXkOp99hpd8+PwAe\nVtWd7meWHuZnmtbsK4eNH8HwC6DfODvpmy7viauOpUc3W88gEIFMKDtU/XE6mBsUA8c122cogIh8\ngtN8dKeqvtX8jUTkOuA6gAEDBgQl2C5v8b/BVw2n/QqyRoQ7GmOCrm9GcrhDiBrBTASBfv4Q4DSc\neQkfichoVd3lv5OqPgo8Cs6EslAHGbUaRggl9YB590H2aEsCJmZs3L6Ppxds4uqTB5LTo1u4w4lo\nAScCEUlU1eoOvPcWINfvcY67zV8x8Jmq1gIbRWQtTmL4vAOfY1pSVOCMEPJfNL5sn5WDNjGjorKW\nxz/ZyPGDeloiaEe71UdFZIKILAPWuY/HisiDAbz358AQEckTkQRgGjCr2T6v4FwNICK9cZqKbIhq\nZ1j2UtMkAM7IoMJ54YnHmBBrnEtgI4faFUgZ6geAyUA5gKouAU5v70WqWgfcALwNrAJeUNUVInKX\niExxd3sbKBeRlcBc4OeqWt7xwzAHqdnj3rFy0CY2pSfF0zs10UYOBSCQpiGPqm5qVq/D19rO/lT1\nDeCNZttu97uvwM/cP9NZVKHoc8geCyOn2gghE7MG9UnhqzK7ImhPIImgSEQmAOrODfgxsDa4YZnD\nUroKytfB+ffCsdeGOxpjwubIPiksLNyJqlLrUxLibBWzlgSSCK7HaR4aAGwD3nO3mUi18hVAYPiU\ndnc1piv73dRRxHk9VNb4GH77W1x63AB+/81RVpG0mUASQZ2qTgt6JKbzrHwVjjgJUm2itoltDesY\nx3mFb+b34z+fbWZUvwwuPc7mI/kLJBF8LiJrgOeBl1V1T3svMGHQMGegrhbKVsMJN4Q7ImMiRrzX\nw33fzWfH/lrunLWCMTkZjOqfEe6wIkZAK5SJyIk4wz+nAIuB51Q1wNrFnctWKKNpKenKcti/Ez59\nuOn6AXFJcMVr1jlsjJ8d+2o4/4F5eET45JYzAGdVs1hoKjrkFcoaqOp8YL6I3An8FXgGCEsiiHlF\nBTBjsjtHoI0k7qt1koUlAmMa9UxJ4B+XH8NjH28EYHHRLm7571Iev/JY+nWP3ZIUgUwoSxWR74nI\na0ABUAacGPTITMtWvurUDGqeBDxx2JwBY9o3Jqc7908bB0CvlAQKy/fx29dWhDmq8ArkimA58Brw\nJ1W1aanhltzdvSOAWilpYw5Dbs9u/PiMIfz57TW8v3obZwzLCndIYRFIIhik6t/4bMKq3p3Ld9ot\nkJptJ31jDtMPJg7i5S+K+dXLy7njgnrOHd033CGFXFuL19+rqjcD/xWRgxqjA1mhzARB6Srokeck\nAmPMYUuI8/CnC8fyi5eWUFi+H4DinfuprPExJCstzNGFRltXBM+7tx1amcwEWdka6DMs3FEY06Uc\nc0QP5tx8GgD19co1MxZSXedj1o9PJj0pPrzBhUCrncWqWuDeHa6qc/z/gOGhCc804auF8vXQ56hw\nR2JMl+XxCL/75iiKdlbys+cX89byrcxbVxbusIIqkMIbV7ew7ZrODsQEYMcGZ/H5TMvDxgTThLye\n3DJpGO+tKmX6vxdxx6yuPaqorT6Ci3EmkeWJyMt+T6UBu1p+lQmqstXOrV0RGBN0PzhlEOeMzGJf\nta/LF6trq4+gAGcNghzgYb/te4AvgxmUaUXZGkCgtyUCY0LhiF4pjfcLNu7g6U838deL8/F6utZM\n5FYTgapuBDbiVBs1kaB0FXQfAAm27J4xobZ9bzWvLfmaM4b14VvjcsIdTqdqq2noQ1U9VUR20nQa\nq+CsKdMz6NGZpmzEkDFhM2lkNsP7pvPX99ZR51N6pyZy+rCuUeG3rYavhuUoewN9/P4aHptQ8tU5\ni81kWiIwJhw8HuHn3xjKpvL9/Pylpfztg/XhDqnTtNU01DCbOBf4WlVrRORkYAzwb2B3COIzDXZu\ndArN2RWBMWFzxrAsCn51JtV19SR2oQ7kQI7kFZxlKo8EngCGAP8JalTmYI0jhiwRGBNOmelJ5Pbs\nRo+UBO57Zw2vLy0Jd0iHLZBaQ/WqWisi3wYeVNUHRMRGDYXKho+g8CMoWew8rrILMWMiQbzXw+xl\nJXxZtIvzx0R3faJArgjqROQi4HJgtrut68+5jgRLnoOnLoCP/gzr3nW2PTvNWZPAGBN2Zw/P4tMN\n5eyuqg13KIcl0JnFp+OUod4gInnAs8ENywAw/4GDt/lqnAVnjDFhd9aILGp9ykdro7sERbuJQFWX\nAz8BForIMKBIVX8f9MhiXflXsG2lLThjTAQ7ekAPeqYk8N7KbeEO5bC020cgIhOBp4EtOHMIskXk\nclX9JNjBxbT5D4A3Hi56EspW2YIzxkQgr0c4f3RfqmqddUIKt++jX/fkqCtJEUhn8V+A81R1JYCI\nDMdJDC0ugmwOQ8Oi9OKFL56God+AYec5f8aYiPS7b45qvH/mfR8yJDOV/15/IimJAS0JHxECSVsJ\nDUkAQFVXAQnBCylGrXsPHv8GzLkL3rsD1AdfzbGOYWOiyK/OG87abXu4beYyVA9azytiBZIIvhCR\nR0TkZPfv71jRuc634CFoviKor846ho2JItecnMdNZw3llcVf85+CzeEOJ2CBJILpwAbgF+7fBuCH\nwQwq5tT7YOtypzPYOoaNiWo/On0wpw7tw29nraS+PjquCtpsxBKR0cCRwExV/VNoQopBa9+G/WVw\nxu1Od7x1DBsTtTwe4a8X5zQlRx4AABniSURBVPO3D9bj8QgPzlnHgg3l/OcHx4c7tFa1VX30Vzgr\nkX0BHCsid6nq4yGLLJZ8/i9I6wsn/RS80dPBZIxpWY+UBG47fwQAe6rrWLhpJ6qKSGSuY9BW09D3\ngDGqehFwLHB9R99cRCaJyBoRWS8it7Sx33dEREUkdkYiFRXAvHvhwz85ncKDz7YkYEwXlJWeRE1d\nPbv2R+7s47bOPNWqug9AVctEpEMDY0XEi7Oy2dlAMfC5iMzyH4Hk7pcG/BT4rEORR7P1c+CZi5yR\nQQ2WvQBHX25NQcZ0MdnpSQBs3V1Fj5TIHHDZ1sl9kIi87P7NBI70e/xyG69rMAFYr6obVLUGeA6Y\n2sJ+vwPuBqo6HH20Kvhn0yQA4Ku1EULGdEHZGYmAkwgiVVtXBN9p9vihDr53f6DI73ExcJz/DiJy\nNJCrqq+LyM9beyMRuQ64DmDAgAEdDCMC7W6YpC1AvY0QMqYLy+nRjYlDepMc7w13KK1qa2GaOcH8\nYLep6T7gyvb2VdVHgUcBxo8fHx3jsVqzZxtsXQb5l0GvPBshZEwXl5WexNPXHNf+jmEUzN7JLTir\nmzXIcbc1SANGAR+4PenZwCwRmaKqC4MYV3itmgUonPgjyBwe7miMMSagCWWH6nNgiIjkiUgCMA2Y\n1fCkqlaoam9VHaiqA4FPga6dBABWvgq9h9pKY8bEkGufXMj1/14U7jBaFXAiEJHEjryxqtYBNwBv\nA6uAF1R1hYjcJSJTOhZmF7G3DDZ9AiO+CRE6ntgY0/lUlcLy/eEOo1WBlKGeADwGZAADRGQscK2q\n/ri916rqG8Abzbbd3sq+pwUScNQpKoCv3nfa/9e+69QT6nVkuKMyxoRQVkYSXxbtCncYrQqkj+AB\nYDLOIvao6hIROT2oUXUVRQUwYzL4qptuf+1G6DnIOoeNiRHZ6Uns2FdDdZ2PxLjIGz0USNOQR1U3\nNdvma3FP01ThPGdpyeZsuUljYkrDpLLS3dXt7BkegVwRFLnNQ+rOFv4xsDa4YXURAyc6cwTU58wT\nQKC+zuYMGBNjhvdN56JjcvB4IrNvMJBEcD1O89AAYBvwHodQdygm5U6A9P4QnwRTH3a2Fc6zOQPG\nxJjRORn8+aKx4Q6jVe0mAlUtxRn6aTqqZh9UFMGpvzxw4rcEYExMUlVqfPUR2UcQyKihfwIHzeZV\n1euCElFXsm0FoNA3cn8JGGNCY9zv3uXCo3P49eQR4Q7lIIE0Db3ndz8J+BZNawiZ1pQscW4tERgT\n87onx0ds4blAmoae938sIk8DHwctoq6kZDF06wXp/cIdiTEmzLLSk9gWoYngUEpM5AFZnR1Il1Sy\nxLkasFnExsS87Iyk6L0iEJGdHOgj8AA7gFZXGzOuumooXQUnnhXuSIwxESA7PYltu6sjcsnK9hav\nF2AsB6qG1qtqdJeBDpXSlc6cAesfMMYAE4f0ITHeS61PSYiLokSgqioib6jqqFAF1GVYR7Exxs/J\nQ3pz8pDe4Q6jRYGMGlosIuNU9cugRxPtigpgzRvOyX/la+BNdCqO9hwU7siMMRHg3ZXb+PGzXwBw\n+lGZ/P2yY8IckaPVRCAicW4p6XE4C89/BezDWV9RVfXoEMUYHYoKYMb5B9cWemoqXDHLJpIZYxjQ\nsxtXnDCQlSW7eWvFVsr2VNMnrUMV/oOirVFDBe7tFOAo4DzgIuBC99b4K5znLEAPOLnSZQXmjDGu\no7LTuPW84dx67nBUYe7q0nCHBLTdNCQAqvpViGKJbgMnOsNEVcEbjxWYM8a0ZnjfNIZlp1FRWdv+\nziHQViLoIyI/a+1JVb0vCPFEr+zRgMARJ8JZv3W2WYE5Y0wLRIQ3fzoxYoaRtpUIvEAqTdo5TKu2\nfOGUmz7xp1ZgzhjTroYkUFNXT0JcMJePb19biaBEVe8KWSTRbvN853bAceGNwxgTFVSVb/99Pkdl\npfHH74wJayxtpSG7EuiIzZ9C5ghI7hHuSIwxUUBE6Nc9mfdWlVJfH955um0lgjNDFkW0q/c5w0cH\nnBDuSIwxUeScEVls31vNtH9+yuWPfUbF/vB0HreaCFR1RygDiWrbVkD1bksExpgOOXN4Fqcf1Yda\nXz17q+vQg5d+CYlAZhablhQVHBgVtOIVZ1t8cnhjMsZEldTEOJ64KvyDSiwRHIqiAnjyAqfCqHhA\n653t/73WZhEbYw7J0uJdzJhfyC2ThpGZnhTSzw7vmKVoVTjPSQKoM2S04XLOZhEbYw7Rjn01vPzF\nFjbv2B/yz7YrgkMxcKJ7JeBzZg7bLGJjzGHKznCuAsKxeI0lgkORc6wzTDQ1Cy74q7PNZhEbYw5D\nttsctLXCEkF0qCiC/dvh1F/aLGJjTKfISI4nMc4TlnWNrY/gUGxa4NweYcNFjTGdQ0TI651CXRgm\nl9kVwaHYvAAS052ZxMYY00neuvGUsHxuUK8IRGSSiKwRkfUictCC9yLyMxFZKSJLRWSOiBwRzHg6\nzeYFkHsceLzhjsQYYw5b0BKBiHiBh4FzgRHAJSLS/Cf0l8B4VR0DvAT8KVjxdJr9O6BsNQw4PtyR\nGGO6mFlLvub7jxegGtrmoWBeEUwA1qvqBlWtAZ4DpvrvoKpzVbVh0OynQE4Q4+kcmz91bo84Mbxx\nGGO6nNLdVXy0toxdIa45FMxE0B8o8ntc7G5rzTXAmy09ISLXichCEVlYVlbWiSEGqKgA5t3r3K54\nGcTrFJozxphOFK65BBHRWSwilwHjgVNbel5VHwUeBRg/fnxor5mKCmDGZPBVN93+zEVWTsIY06ka\n5xLsrmJ43/SQfW4wrwi2ALl+j3PcbU2IyFnAbcAUVa1u/nzYFc5zSkc0Z+UkjDGdLMtNBNtCPKks\nmIngc2CIiOSJSAIwDZjlv4OIjAP+gZMESoMYy6FrWJQenBIS3kSnacjKSRhjOllWehJH9kkhzhva\nKV5BaxpS1ToRuQF4G2f948dVdYWI3AUsVNVZwJ9x1kV+0V2/c7OqTglWTIckdwIk94S0vjD5Pmeb\nlZMwxgRBQpyHOTefFvLPDWofgaq+AbzRbNvtfvfPCubnd4q9ZU45iZNvtHISxpguyUpMtGfrEue2\n79jwxmGMiQl/ems11z21MKSfaYmgPSVLndvsMeGNwxgTE3bur2XRpp0h/UxLBO0pWQI9BkJy93BH\nYoyJAdnpSZTvq6G6LnRzlSwRtKdkiTULGWNCJjsjEYDS3aEbTW+JoC1VFbBzoyUCY0zINM4lCOHs\nYksEbdm6zLm1RGCMCZEBPbtx0uBexHk9FG7fx20zlwX9MyOixETEKnFHDGVbIogGtbW1FBcXU1UV\n+hWeIkFSUhI5OTnEx8eHOxRzGAb1SeWZa53qxve8vYaZX27h998aHdTPtETQXFHBgQlj6+dAQprT\nPJTaJ9yRmXYUFxeTlpbGwIEDkYbZ4DFCVSkvL6e4uJi8vLxwh2M6SXKCl/01PqpqfSTFB2/9E0sE\n/ooKYMb5B9cWenKKFZiLAlVVVTGZBMBZ5rBXr16EpTqvCZo+qU7HcdmeanJ7dgva51gfgb8lz1mB\nuSgXi0mgQSwfe1fVOy0BgLK9wR1BFNtXBP7NQHvLYPF/nO3idZehFKivswJzxpiw6O1eEWzfY4kg\nOFprBvLGw7jLYewlzmMrMGc64Oqrr2b27NlkZmayfPnyFvfxer2MHn2g8++VV16hsLCQqVOnkpeX\nR3V1NdOmTeOOO+7ggw8+aNxeVVXF5MmTueeee0J1OCbMhmalMfd/T6Ovu2BNsMRuIiicB74WloOr\nr4eMHCswZw7JlVdeyQ033MD3v//9VvdJTk5m8eLFTbYVFhYyceJEZs+ezb59+8jPz+eCCy4AaNxe\nWVnJuHHj+Na3vsVJJ50U1OMwkSEp3kte75Sgf07sJoKBE0E8oD6n6ceagbqci/+x4KBtk8f05fIT\nBlJZ4+PKJwoOev7CY3K4aHwuO/bVcP2/FzV57vkfntDuZ55yyikUFhYecswAKSkpHHPMMaxfv57M\nzMzG7cnJyeTn57Nly0HrO5ku7N+fbiIzLZFzRmYH7TNiNxHkToCsUVBZDhc+4WyzZiATApWVleTn\n5wOQl5fHzJkzmzxfXl7Op59+ym9+85smo4B27tzJunXrOOWUU0Iarwmvxz/ZyLDsNEsEQVNdAbnH\nWzNQF9XWL/jkBG+bz/dMSQjoCuBQtNQ0BDBv3jzGjRuHx+PhlltuYeTIkXzwwQfMmzePsWPHsm7d\nOm688Uays4N3QjCRp3dqItv3tDCasRPF7vDR+nqo2OL0BxgTJEVFReTn55Ofn88jjzzS5r4TJ07k\nyy+/ZNGiRUyfPr3J9iVLlrBixQoee+yxFpOI6br6pCay3YaPBsnebVBfa4nABFVubm6nnbjz8vK4\n5ZZbuPvuu3n22Wc75T1N5OudmhD0eQSxe0VQUezcZuSGNw7TpVxyySWccMIJrFmzhpycHB577LFO\nff/p06fz0UcfHXaHtIkevVMT2VNVF9T1CURVg/bmwTB+/HhduLATlnFb/jK8dBVcPx+yRh7++5mw\nW7VqFcOHDw93GGFl/w26nn3VdXhESE44vFpDIrJIVce39FzsNg01XhFY05AxJnKlJAb/NB3DTUNF\nkJgOSRnhjsQYY1pVuruK381eyfItFUH7jBhOBMV2NWCMiXjVdfU89vFGVnxtiaDzVRRZR7ExJuL1\nSXMLz+0N3lyCGE4EdkVgjIl8SfFeUhPjKAtiBdLYTATVe6FypyUCY0xU6J2aENRJZbE5asjmEJgg\nKC8v58wzzwRg69ateL1e+vRxljhdsmQJY8eOpa6ujuHDh/Pkk0/SrVu3xpLUdXV15OXl8fTTT9O9\ne/dwHoaJQH3SEqmsCd48gti8ImhIBN0tEcS8ogKYd69ze5h69erF4sWLWbx4MdOnT+emm25qfJyS\nksLixYtZvnw5CQkJjeUmGuoOLV++nJ49e/Lwww8fdhym63nuuhN47Mpjg/b+MXpFUOTcWtNQ1/Xm\nLbB1Wdv7VO+GbctB652S5FmjnCHFrckeDef+8bBDmzhxIkuXLj1o+wknnNDidmO8nuAuQxq7VwTi\nhVSr4hjTqiqcJADObVXwhuc1qKur480332yyQhmAz+djzpw5TJkyJegxmOgzd00pP3rmC2p99UF5\n/9i9IkjvB97YPPyYEMgv96ICeHKKs1ypNwG+86+glSL3X4Ng4sSJXHPNNU22b9myheHDh3P22WcH\n5fNNdNuys5LXl5Vw+wUjyErv/GUrg3pFICKTRGSNiKwXkVtaeD5RRJ53n/9MRAYGM55GpSsB6ZR2\nYRPFcifAFbPgjNuc2yCuR9HQF7B48WIefPBBEhISmmzftGkTqmp9BKZFDYvYB2sIadASgYh4gYeB\nc4ERwCUiMqLZbtcAO1V1MPAX4O5gxUNRAXx0D7zzG6ftuGKz82vQkkFsy50AE28O+6JE3bp144EH\nHuDee++lrq4urLGYyNMnzfnhEKwhpMG8IpgArFfVDapaAzwHTG22z1TgSff+S8CZItL5vSJFBfDE\nefD+72D+Awe2+2qc5SmNiQDjxo1jzJgxttaAOUif1CQykuOpqo2+PoL+QJHf42LguNb2UdU6EakA\negHb/XcSkeuA6wAGDBjQ8UgK50F9wxhcAY8XVG2hehM0d955Z5PHe/fubXG/5ttfe+21YIVkotiA\nXt1Ycsc5QXv/qOgtVdVHgUfBWY+gw28wcCLEJR7oFJz0R2fReluo3hhjgpoItgD+M7Zy3G0t7VMs\nInFABlDe6ZE0dAoWzrOTvzHGNBPMRPA5MERE8nBO+NOAS5vtMwu4AlgAXAi8r8FaMi13giWAGKCq\nBKObKRpE22qDJnIErbNYVeuAG4C3gVXAC6q6QkTuEpGGWTOPAb1EZD3wM+CgIabGBCopKYny8vKY\nPCGqKuXl5SQldf4Yc9P1xe6axabLqa2tpbi4mKqqqnCHEhZJSUnk5OQQHx8f7lBMBLI1i01MiI+P\nJy8vL9xhGBN1YrPWkDHGmEaWCIwxJsZZIjDGmBgXdZ3FIlIGbDrEl/em2azlKNZVjsWOI/J0lWOx\n42jqCFXt09ITUZcIDoeILGyt1zzadJVjseOIPF3lWOw4AmdNQ8YYE+MsERhjTIyLtUTwaLgD6ERd\n5VjsOCJPVzkWO44AxVQfgTHGmIPF2hWBMcaYZiwRGGNMjIuZRCAik0RkjYisF5GoqXIqIrkiMldE\nVorIChH5qbu9p4i8KyLr3Nse4Y41ECLiFZEvRWS2+zhPRD5zv5fnRSQh3DEGQkS6i8hLIrJaRFaJ\nyAnR+J2IyE3uv6vlIvKsiCRFy3ciIo+LSKmILPfb1uJ3II4H3GNaKiJHhy/yplo5jj+7/7aWishM\nEenu99yt7nGsEZFvdEYMMZEIRMQLPAycC4wALhGREeGNKmB1wM2qOgI4HviRG/stwBxVHQLMIXpK\neP8Upyx5g7uBv6jqYGAncE1Youq4+4G3VHUYMBbnmKLqOxGR/sBPgPGqOgrw4qwbEi3fyQxgUrNt\nrX0H5wJD3L/rgL+HKMZAzODg43gXGKWqY4C1wK0A7v/704CR7mv+5p7fDktMJAJgArBeVTeoag3w\nHDA1zDEFRFVLVPUL9/4enBNOf5z4n3R3exL4ZngiDJyI5ADnA/9yHwtwBvCSu0u0HEcGcArOehqo\nao2q7iIKvxOcCsTJ7gqB3YASouQ7UdWPgB3NNrf2HUwFnlLHp0B3Eekbmkjb1tJxqOo77pouAJ/i\nrPAIznE8p6rVqroRWI9zfjsssZII+gNFfo+L3W1RRUQGAuOAz4AsVS1xn9oKZIUprI74K/ALoN59\n3AvY5fcPPlq+lzygDHjCbeb6l4ikEGXfiapuAe4BNuMkgApgEdH5nTRo7TuI5nPA1cCb7v2gHEes\nJIKoJyKpwH+BG1V1t/9z7vKeET0OWEQmA6WquijcsXSCOOBo4O+qOg7YR7NmoCj5Tnrg/MLMA/oB\nKRzcRBG1ouE7aI+I3IbTPPxMMD8nVhLBFiDX73GOuy0qiEg8ThJ4RlVfdjdva7i0dW9LwxVfgE4C\npohIIU7T3Bk47ezd3WYJiJ7vpRgoVtXP3Mcv4SSGaPtOzgI2qmqZqtYCL+N8T9H4nTRo7TuIunOA\niFwJTAa+57eWe1COI1YSwefAEHc0RAJOZ8usMMcUELcd/TFglare5/fULOAK9/4VwKuhjq0jVPVW\nVc1R1YE4//3fV9XvAXOBC93dIv44AFR1K1AkIke5m84EVhJl3wlOk9DxItLN/XfWcBxR9534ae07\nmAV83x09dDxQ4deEFHFEZBJOM+oUVd3v99QsYJqIJIpIHk7nd8Fhf6CqxsQfcB5O7/tXwG3hjqcD\ncZ+Mc3m7FFjs/p2H074+B1gHvAf0DHesHTim04DZ7v1B7j/k9cCLQGK44wvwGPKBhe738grQIxq/\nE+C3wGpgOfA0kBgt3wnwLE7fRi3OVdo1rX0HgOCMHPwKWIYzUirsx9DGcazH6Qto+H/+Eb/9b3OP\nYw1wbmfEYCUmjDEmxsVK05AxxphWWCIwxpgYZ4nAGGNinCUCY4yJcZYIjDEmxlkiMBFHRHwistjv\nb2Ab+w70r9p4GJ/5gVvNcYmIfOI3R6Aj7zFdRL7v3r9SRPr5Pfevzih02CzOz0UkP4DX3Cgi3Q73\ns03XZYnARKJKVc33+ysM0ed+T1XH4hQr+3NHX6yqj6jqU+7DK3HKNjQ8d62qruyUKA/E+TcCi/NG\nnIJyxrTIEoGJCu4v/3ki8oX7d2IL+4wUkQL3KmKpiAxxt1/mt/0fAZTt/QgY7L72TLew3DK3bnyi\nu/2P4qwRsVRE7nG33Ski/ysiFwLjgWfcz0x2f8mPd68aGk/e7pXDQ4cY5wL8Co6JyN9FZKE46wv8\n1t32E5yENFdE5rrbzhGRBe5/xxfdOlYmhlkiMJEo2a9ZaKa7rRQ4W1WPBi4GHmjhddOB+1U1H+dE\nXCwiw939T3K3+4DvtfP5FwDLRCQJp1b8xao6GqfY3PUi0gv4FjBSnXrx/+f/YlV9CWfW8ffcK5pK\nv6f/6762wcXAc4cY5yScWc0NblPV8cAY4FQRGaOqDwBfA6er6uki0hv4NXCW+99yIfCzdj7HdHFx\n7e9iTMhVuidDf/HAQ26buA8Y2sLrFgC3ibPuwcuquk5EzgSOAT53yumQTOvF4J4RkUqgEPgxcBRO\nUba17vNPAj8CHgKqgMfEWWltdqAHpqplIrLBrXezDhgGfOK+b0fiTABScUpdNPiuiFyH8/91X5xF\nmJY2e+3x7vZP3M9JwPnvZmKYJQITLW4CtuGsBubBORE3oar/EZHPcBa/eUNEfohTY+ZJVb01gM/4\nnqoubHggIj1b2klV60RkAk6RtguBG3CqqQbqOeC7ODV+ZqqqukXfAo4TZ92APwMPAt92C5D9L3Cs\nqu4UkRlAUguvFeBdVb2kA/GaLs6ahky0yABKVLUeuBxnWcUmRGQQsMFtDnkVp4lkDnChiGS6+/QU\nkSMC/Mw1wEARGew+vhz40G1Tz1DVN3AS1NgWXrsHSGvlfWfirANwCU5SoKNxqlMk7Dc41UOHAek4\n6yJUiEgWztKMLcXyKXBSwzGJSIqItHR1ZWKIJQITLf4GXCEiS3CaU/a1sM93geUishgYhbM04Uqc\nNvF3RGQpzlqwAS1RqKpVwFXAiyKyDGdltUdwTqqz3ff7mJbb2GcAjzR0Fjd73504S44eoaoF7rYO\nx+n2PdwL/FxVlwBf4lxl/AenuanBo8BbIjJXVctwRjQ9637OApz/niaGWfVRY4yJcXZFYIwxMc4S\ngTHGxDhLBMYYE+MsERhjTIyzRGCMMTHOEoExxsQ4SwTGGBPj/j99inD+Dz9iIgAAAABJRU5ErkJg\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzkkMy8kY6KT",
        "colab_type": "code",
        "outputId": "ef476e9c-1719-4d23-d875-95832892d62e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "y_class = lr_probs > a\n",
        "y_class"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True,  True, False, False,  True, False, False, False,  True,\n",
              "        True, False,  True, False,  True,  True,  True, False,  True,\n",
              "       False,  True,  True, False, False,  True, False,  True,  True,\n",
              "        True, False,  True,  True,  True, False,  True, False, False,\n",
              "        True,  True,  True, False, False, False, False,  True, False,\n",
              "       False, False,  True, False, False, False,  True,  True, False,\n",
              "       False,  True, False, False, False,  True,  True, False,  True,\n",
              "       False, False, False, False, False,  True,  True, False, False,\n",
              "        True,  True,  True,  True, False,  True, False, False, False,\n",
              "       False,  True, False,  True, False,  True, False,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True, False,  True, False,\n",
              "        True,  True, False,  True, False, False, False,  True, False,\n",
              "        True, False, False,  True,  True, False, False,  True,  True,\n",
              "       False, False,  True, False, False, False, False,  True,  True,\n",
              "        True,  True,  True,  True, False,  True, False, False, False,\n",
              "        True, False, False,  True, False,  True,  True,  True, False,\n",
              "       False, False, False,  True,  True, False,  True, False, False,\n",
              "       False,  True,  True, False, False, False,  True, False,  True,\n",
              "        True, False, False,  True, False, False,  True, False, False,\n",
              "        True,  True, False, False, False,  True, False, False,  True,\n",
              "       False,  True, False,  True, False,  True,  True, False, False,\n",
              "        True,  True,  True, False,  True,  True, False, False,  True,\n",
              "        True, False, False,  True,  True,  True, False, False,  True,\n",
              "       False, False,  True,  True,  True, False,  True, False, False,\n",
              "        True,  True,  True,  True, False,  True, False,  True,  True,\n",
              "       False, False, False, False,  True, False, False,  True,  True,\n",
              "        True,  True,  True, False,  True,  True, False, False,  True,\n",
              "       False, False,  True, False,  True, False,  True,  True, False,\n",
              "        True,  True,  True, False,  True, False, False, False,  True,\n",
              "       False, False,  True, False, False, False, False, False, False,\n",
              "       False, False,  True, False,  True, False, False, False,  True,\n",
              "        True, False, False, False, False, False,  True, False, False,\n",
              "        True, False,  True, False, False, False,  True,  True, False,\n",
              "        True,  True, False,  True,  True, False, False, False, False,\n",
              "       False,  True,  True, False,  True,  True,  True,  True,  True,\n",
              "       False,  True,  True, False,  True,  True,  True,  True,  True,\n",
              "        True, False,  True,  True,  True,  True,  True,  True,  True,\n",
              "       False, False,  True, False, False,  True, False,  True, False,\n",
              "       False, False, False,  True,  True, False,  True,  True,  True,\n",
              "       False, False,  True, False, False,  True, False, False,  True,\n",
              "        True,  True, False,  True, False,  True,  True,  True, False,\n",
              "        True, False, False, False,  True,  True, False,  True,  True,\n",
              "        True,  True, False, False,  True, False,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True, False,  True, False,\n",
              "        True, False,  True,  True, False, False,  True, False,  True,\n",
              "        True, False,  True, False,  True,  True, False, False,  True,\n",
              "        True, False,  True, False,  True, False,  True, False,  True,\n",
              "       False, False, False, False, False,  True,  True, False, False,\n",
              "       False, False, False,  True,  True,  True,  True,  True, False,\n",
              "        True,  True, False, False,  True,  True,  True,  True, False,\n",
              "        True,  True,  True, False,  True,  True, False,  True,  True,\n",
              "        True,  True, False, False,  True,  True, False, False, False,\n",
              "        True,  True, False, False, False,  True,  True, False, False,\n",
              "       False, False,  True, False,  True, False,  True,  True, False,\n",
              "        True,  True,  True, False,  True,  True, False, False, False,\n",
              "        True,  True, False,  True, False])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tAA2Afr6Y0Q",
        "colab_type": "text"
      },
      "source": [
        "## Precision-Recall curves\n",
        "\n",
        "Precision-Recall is a useful measure of success of prediction when the classes are very imbalanced. In information retrieval, precision is a measure of result relevancy, while recall is a measure of how many truly relevant results are returned.\n",
        "\n",
        "The precision-recall curve shows the tradeoff between precision and recall for different threshold. A high area under the curve represents both high recall and high precision, where high precision relates to a low false positive rate, and high recall relates to a low false negative rate. High scores for both show that the classifier is returning accurate results (high precision), as well as returning a majority of all positive results (high recall).\n",
        "\n",
        "A system with high recall but low precision returns many results, but most of its predicted labels are incorrect when compared to the training labels. A system with high precision but low recall is just the opposite, returning very few results, but most of its predicted labels are correct when compared to the training labels. An ideal system with high precision and high recall will return many results, with all results labeled correctly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEGUF8c-96K-",
        "colab_type": "text"
      },
      "source": [
        "Note that the **precision may not decrease with recall**. The definition of precision ($\\frac{T_p}{T_p + F_p}$) shows that lowering the threshold of a classifier may increase the denominator, by increasing the number of results returned. If the threshold was previously set too high, the new results may all be true positives, which will increase precision. If the previous threshold was about right or too low, further lowering the threshold will introduce false positives, decreasing precision.\n",
        "\n",
        "Recall is defined as $\\frac{T_p}{T_p+F_n}$, where $T_p+F_n$ does not depend on the classifier threshold. This means that lowering the classifier threshold may increase recall, by increasing the number of **true** positive results. It is also possible that lowering the threshold may leave recall unchanged, while the precision fluctuates."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4wfHBOoBLWK",
        "colab_type": "text"
      },
      "source": [
        "The relationship between recall and precision can be observed in the stairstep area of the plot - at the edges of these steps a small change in the threshold considerably reduces precision, with only a minor gain in recall.\n",
        "\n",
        "**Average precision** (AP) summarizes such a plot as the weighted mean of precisions achieved at each threshold, with the increase in recall from the previous threshold used as the weight:\n",
        "\n",
        "$\\text{AP} = \\sum_n (R_n - R_{n-1}) P_n$\n",
        "\n",
        "\n",
        "where $P_n$ and $R_n$ are the precision and recall at the nth threshold. A pair $(R_k, P_k)$ is referred to as an operating point.\n",
        "\n",
        "AP and the trapezoidal area under the operating points (Area Under Curve (AUC) [link text](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.auc.html#sklearn.metrics.auc)) are common ways to summarize a precision-recall curve that lead to different results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1eISR03K6bIA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import svm, datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Add noisy features\n",
        "random_state = np.random.RandomState(0)\n",
        "n_samples, n_features = X.shape\n",
        "X = np.c_[X, random_state.randn(n_samples, 200 * n_features)]\n",
        "\n",
        "# Limit to the two first classes, and split into training and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X[y < 2], y[y < 2],\n",
        "                                                    test_size=.5,\n",
        "                                                    random_state=random_state)\n",
        "\n",
        "# Create a simple classifier\n",
        "classifier = svm.LinearSVC(random_state=random_state)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "#Predicts confidence scores for samples\n",
        "y_score = classifier.decision_function(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYLVl2d15Mkd",
        "colab_type": "code",
        "outputId": "c4440a4e-580d-4dc9-a094-289e9530cc72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from sklearn.metrics import average_precision_score\n",
        "average_precision = average_precision_score(y_test, y_score)\n",
        "\n",
        "print('Average precision-recall score: {0:0.2f}'.format(\n",
        "      average_precision))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average precision-recall score: 0.88\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7LJwygu37dY",
        "colab_type": "code",
        "outputId": "d44b7941-c029-4928-e37c-54c3c2e703f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        }
      },
      "source": [
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from inspect import signature\n",
        "\n",
        "precision, recall, thresholds = precision_recall_curve(y_test, y_score)\n",
        "\n",
        "# In matplotlib < 1.5, plt.fill_between does not have a 'step' argument\n",
        "step_kwargs = ({'step': 'post'}\n",
        "               if 'step' in signature(plt.fill_between).parameters\n",
        "               else {})\n",
        "plt.step(recall, precision, color='b', alpha=0.2,\n",
        "         where='post')\n",
        "plt.fill_between(recall, precision, alpha=0.2, color='b', **step_kwargs)\n",
        "\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.title('2-class Precision-Recall curve: AP={0:0.2f}'.format(\n",
        "          average_precision))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, '2-class Precision-Recall curve: AP=0.88')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAActUlEQVR4nO3debhcVZnv8e/PMIcQxBCUjAxJa5gh\nMrTdgoo0IAQfUSAyKk2csLFFvd5uLwZsW9ErXryiEoUGAYmBVu8Rg1HGOKEJTUAShA6BkAQQwhCG\nMAXe+8dahxSVc3btqpx9qs7J7/M89ZyqvVftemvVqXr3WmvvtRURmJmZ9eZ17Q7AzMw6mxOFmZkV\ncqIwM7NCThRmZlbIicLMzAo5UZiZWSEnigFM0imSftvuOPqapIWSDmpQZqykZyQN6aewKifpfkkH\n5/vTJV3e7pjMwImi30naVNJFkpZKelrSAkmHtTuuMvIP2XP5B/qvki6RtGVfv05E7BIRNzUo80BE\nbBkRL/f16+cf6Zfy+3xS0u8lHdDXr7OhyP8nayS9qW55n9SzpA/m79Ozkn4maZuCsu+U9F+SnpK0\nRNK0uvWflHRfXj9f0t81G89g5ETR/zYClgEHAsOBLwCzJI1vY0zNODIitgT2BiaT4n8NJQP9f+vH\n+X2OAG4ErmpzPH1O0kb98BpDgaOBVcAJPRTprudtgd8CP5GkJra/C3AhcCKwHbAa+E4vZTcGfprL\nDweOBc6TtEdevx/wVeD9ef1FwE8HU6u1VQP9yzzgRMSzETE9Iu6PiFci4hrgPmCf3p4jaYykn0h6\nVNJjkr7dS7nzJS3Le0O3Svr7mnX75j2kp3Jr4Ly8fDNJl+ftPilpnqTtSryPFcC1wK55OzdJ+rKk\n35G+rDtKGp5bTw9JWiHp32q/dJJOk3RXblktkrR3Xl7bBdNb3OMlRfePnaTtJXVJelzSYkmn1bzO\ndEmzJP0wv9ZCSZMbvcf8PtcAVwCjJG1bs80jcmuwe09495p1PX5eknaSdENetlLSFZK2LhNHPUlH\n5dd/StK9kg6tr7ua9355XZ2dKukB4AZJ10o6vW7bt0t6X77/Zkm/zvV6t6Rjmgz1aOBJ4Bzg5N4K\nRcRLwKXAG4E3NLH944GfR8TciHgG+F/A+yQN66HsNsBWwGWRzAPuAibl9eOBhRFxa6QpK35I2lEY\n2UQ8g5ITRZvlH+WJwMJe1g8BrgGWkv6RRwEze9ncPGBP0hfiR8BVkjbL684Hzo+IrYCdgFl5+cmk\nvacxpC/oR4HnSsQ9BjgcuK1m8YnANGBYjvcSYA2wM7AXcAjwj/n5HwCmAyeRvrxTgMd6eKne4q43\nE1gObE/aI/x3Se+sWT8ll9ka6AJ6TLY9vM9NcoyPAU/kZXsBFwMfIdXZhUCXUrdi0ecl4Cs5xreQ\n6nx6mTjqYtqX9CP22fx+3g7c38QmDsyv/w/AlcDUmm1PAsYBv8itgV+T/pdGAscB38llurt87mjw\nWifn15gJvFlSjztEkjYFTgGWRcRKSX+Xk3Bvt+4uoV2A27u3ExH3Ai+SvlOvERF/zbF8SNIQpW6u\ncaSWDKQdnyGS9suf44eBBcDDDd7j4BcRvrXpBmwMXAdcWFDmAOBRYKMe1p0C/LbguU8Ae+T7c4Gz\ngRF1ZT4M/B7YvUS89wPPkPYQl5Ka+JvndTcB59SU3Q54oXt9XjYVuDHfnwOcUfA6BzeIezwQpK68\nMcDLwLCa9V8BLsn3pwPX1aybBDxX8D6nk35snszbfQw4qGb9d4Ev1T3nbtIPcK+fVw+v817gtl7e\n93Tg8l6edyHwzUZ1V7+dmjrbsWb9MOBZYFx+/GXg4nz/WOA3Pbz2F0v+f48FXgH2rPnMz++lnh8B\nbgD2afI7dD3w0bplK2o/r7p1RwJ/Je3ArAFOq1kn4F+Al/K6lcBbm4lnsN7comgTpT78y0hflNNr\nll+rNLj3jKTjST+CSyN1gTTa5mdyV84qSU+SWgoj8upTSXtZf8ndS0fk5ZeRvsAzJT0o6WtKfbm9\neW9EbB0R4yLi4xFR2/pYVnN/HCkRPtS9F0j6keluxo8B7m30ngrirrU98HhEPF2zbClpb75b7V7h\namAzSRtJOr6mvq+tKTMrIrYmJbw7eW3X4DjgzNo93Px+tqfg85K0naSZSt1wTwGXs/bzaUbZuuvN\nq59TrrNfkFoLkJL5Ffn+OGC/uvd5PKl7qIwTgbsiYkF+fAXwwbr/r1n5/2lkRLwzIm5t8r08Q2qR\n1toKeLq+oKQ3k1o2JwGbkFojn5P0nlzkVOBDefkmpDGVayRt32RMg44TRRtIEmmgbDvg6Ej9swBE\nxGGRjubZMiKuIH2px6rBwKPSeMTngGOA1+cfuVWkvSQi4r8jYirph/pc4GpJQyPipYg4OyImAX8L\nHEH6IrWidiriZaQWxYj8Q7B1RGwVEbvUrN+p4QZ7ibuu2IPANnX90mNJe5aNtn9FTX2vc/RZRKwk\ndadN19qjdpYBX655X1tHxBYRcSXFn9e/k+pot0hdaSeQP58mFdXds8AWNY97+lGvnzL6SmBq7orZ\njDR43/06N9e9zy0j4mMl4zyJNFb1sKSHgfNIifHwRk+U9Pc1CbynW/f420Jgj5rn7QhsCtzTw2Z3\nBe6JiDmRxgfvJiXJ7s99T+CaiLgnr/8l8BDpe7FBc6Joj++S+oiPrNsj78mfSP+sX5U0VGnw+W09\nlBtGai4/Cmwk6Sxq9rQknSBp24h4hdTUB3hF0jsk7Zb7ZJ8iNbtfWa93B0TEQ8CvgG9I2krS65QG\ncw/MRX4AfEbSPkp2ljSufju9xV33WstI3WdfyfWzO2nvsE/OQ8g/KHNIiRjg+8BHc1+28ufynpyo\nij6vYaQ94FWSRpHGGFpxEamf/V25XkflvWVIferHSdpYacD+/SW2N5vUejiHdBRSd/1eA0yUdGLe\n3saS3irpLY02mJPOTsC+pB/gPUk/1D+ixI5IRPymJoH3dPtNLnoFcGROLEPze/hJXeuy223ABKVD\nZCVpJ9KOUfc4yzzgPZJ2zOvfTWrN3tko3sHOiaKf5R/Dj5C+OA/XdTOtI9J5AkeSBoQfIA3YHttD\n0TnAL0l7UkuB53ltV9ChwEJJz5AGiI/LSeqNwNWkJHEXcDOpO6ovdDfxF5HGS64G3pTf11Wk/vAf\nkboJfkYahK/XW9z1ppL64B8kHQL5xYi4ro/eB8DXgWmSRkbEfOA00oD4E8Bi0nhRo8/rbNJhxatI\ne7I/aSWQiPgTqYvkm3lbN5N+6CEd9bNTjutsUv022t4LOZaDa8vnH9tDSN1SD5K6784l7bGTu+16\nPAiDNIj9/yLizxHxcPeN9BkeoYJzHZoREQtJB2BcQRrnGAZ8vHu9Ulfuv+Sy95LG5L5F+n+/GfhP\n0k4LpAMEZpLG257K5T4SEX/pi1gHMkX4wkVmZtY7tyjMzKyQE4WZmRVyojAzs0JOFGZmVqjyScH6\n2ogRI2L8+PHtDsPMbEC59dZbV0bEto1LrmvAJYrx48czf/78dodhZjagSFra6nPd9WRmZoWcKMzM\nrJAThZmZFXKiMDOzQk4UZmZWyInCzMwKVZYoJF0s6RFJPU7Rm6fx/ZbS9Y3vUL5espmZdZYqWxSX\nkKaI7s1hwIR8m0a6RoOZmXWYyk64i4i5ksYXFDkK+GGkec5vkbS1pDflC9706vnn4Z6erl1lVmCb\nbWBEKxcdNbO2npk9itdeWGd5XrZOopA0jdTqYMSIHZk7t1/is0HihRdSopg6td2RmA1MA2IKj4iY\nAcwAmDhxcuy1V5sDsgFl6VJ4/PF2R2E2cLXzqKcVwJiax6PzMjMz6yDtTBRdwEn56Kf9gVWNxifM\nzKz/Vdb1JOlK4CBghKTlwBeBjQEi4nvAbOBw0oXpV5MuFm9mZh2myqOeCocO89FOn6jq9c3MrG/4\nzGwzMyvkRGFmZoWcKMzMrJAThZmZFXKiMDOzQk4UZmZWyInCzMwKDYi5nsw63cqVrc0n5VltbSBw\nojDrQbM//E8/DQsWQET553hWWxsonChs0Fu9Gp57rrnrmLTyw7/ppjBpUvnyntXWBgonCtsgPP88\nTV/HpNkffrPByonCBr2hQ0ECX8fErDVOFDbojR2bbmbWGh8ea2ZmhZwozMyskBOFmZkV8hiF2QDi\nE/usHZwozNqkv87v8Il9tr6cKMzaqD/O7/CJfba+nCjM2uj5531+h3U+D2abtcnQobD55u2Owqwx\ntyjM2sQnAtpA4RaFmZkVcqIwM7NCThRmZlbIicLMzAo5UZiZWSEnCjMzK+REYWZmhZwozMyskBOF\nmZkVcqIwM7NClU7hIelQ4HxgCPCDiPhq3fqxwKXA1rnM5yNidpUxmW1oWpnOHHwNC1urskQhaQhw\nAfBuYDkwT1JXRCyqKfYFYFZEfFfSJGA2ML6qmMw2VM1OZ+5rWFitKlsU+wKLI2IJgKSZwFFAbaII\nYKt8fzjwYIXxmG2wmp3O3NewsFpVJopRwLKax8uB/erKTAd+JemTwFDg4J42JGkaMA1g5EhPt2nW\nDE9nbuur3YPZU4FLImI0cDhwmaR1YoqIGRExOSImDx++bb8HaTaQjR0L73hHu6OwgazKRLECGFPz\neHReVutUYBZARPwB2Azw8JmZWQepsutpHjBB0g6kBHEc8MG6Mg8A7wIukfQWUqJ4tMKYzKwEHyll\ntSpLFBGxRtLpwBzSoa8XR8RCSecA8yOiCzgT+L6kfyYNbJ8SEVFVTGZWXqceKbVyZfMD7U5g66fS\n8yjyORGz65adVXN/EfC2KmMws9Z06pFSjz8Ov/89rFlTrrwP9V1/vma2ma2jv46UaqV1sHp1ShJl\nk5gP9V1/ThRmto6xY9OtGa2Mazz9NCxYAM12OG+6aXPlbf04UZhZn2l2XAPSj/6kSdXEAx6Y7wtO\nFGbWZ5od1+gvnTowP1A4UZhZn+jUM8CHDgWpMwfmBwonCjPrE62Ma/SHTo1rIGn3FB5mZtbhnCjM\nzKyQE4WZmRVyojAzs0JOFGZmVsiJwszMCjlRmJlZIScKMzMr5ERhZmaFnCjMzKyQE4WZmRXyXE9m\nZn2glYswwcCYztyJwsysDzR7iVYYONOZO1GYmdVp5WJHzV6iFQbOdOZOFGZmPWj1an2DkROFmVkP\nOvVqfe3go57MzOp06tX62sUtCjOzOr4q3mu5RWFmZoWcKMzMrJC7nszM2qSVw3Ch/0/Sc6IwM2uj\nZg/DbcdJek4UZmZt1OxhuO04Sc9jFGZmbTJQDsN1i8LMrE0GymG4pROFpFHAuNrnRESTJ7ibmdn6\naHUAfH2UShSSzgWOBRYBL+fFARQmCkmHAucDQ4AfRMRXeyhzDDA9b+/2iPhg2eDNzDZErcxDBcOG\ntvp6ZVsU7wX+JiJeKLthSUOAC4B3A8uBeZK6ImJRTZkJwP8E3hYRT0gaWT50M7MNU2vzUA0Z0urr\nlR3MXgJs3OS29wUWR8SSiHgRmAkcVVfmNOCCiHgCICIeafI1zMw2KO0YAC/bolgNLJB0PfBqqyIi\n/qngOaOAZTWPlwP71ZWZCCDpd6TuqekR8cuSMZmZbXDaMQBeNlF05VsVrz8BOAgYDcyVtFtEPFlb\nSNI0YBrAyJED4BABM7NBpFSiiIhLJW1CbgEAd0fESw2etgIYU/N4dF5Waznwx7yt+yTdQ0oc8+pe\nfwYwA2DixMlRJmYzM+sbpcYoJB0E/DdpcPo7wD2S3t7gafOACZJ2yEnmONZtlfyM1JpA0ghSIlpS\nNngzM6te2a6nbwCHRMTdAJImAlcC+/T2hIhYI+l0YA5p/OHiiFgo6RxgfkR05XWHSOo+7PazEfFY\n62/HzMz6WtlEsXF3kgCIiHskNTwKKiJmA7Prlp1Vcz+AT+ebmZl1oLKJYr6kHwCX58fHA/OrCcnM\nzDpJ2UTxMeATQPfhsL8hjVWYmdkgV/aopxeA8/LNzMw2IIWJQtKsiDhG0p9JczG9RkTsXllkZmbW\nERq1KM7If4+oOhAzM+tMhedRRMRD+e5KYFlELAU2BfYAHqw4NjMz6wBlJwWcC2yWr0nxK+BE4JKq\ngjIzs85RNlEoIlYD7wO+ExEfAHapLiwzM+sUpROFpANI50/8Ii9reW5zMzMbOMomik+RLjD00zwN\nx47AjdWFZWZmnaLseRQ3AzfXPF7C2pPvzMxsEGt0HsX/iYhPSfo5PZ9HMaWyyMzMrCM0alFclv/+\n76oDMTOzzlSYKCLi1nx3PvBcRLwCIGkI6XwKMzMb5MoOZl8PbFHzeHPgur4Px8zMOk3ZRLFZRDzT\n/SDf36KgvJmZDRJlE8WzkvbufiBpH+C5akIyM7NOUvZ6FJ8CrpL0ICDgjcCxlUVlZmYdo+x5FPMk\nvRn4m7zo7oh4qbqwzMysU5TqepK0BfA/gDMi4k5gvCRPPW5mtgEoO0bxH8CLwAH58Qrg3yqJyMzM\nOkrZRLFTRHwNeAkgzySryqIyM7OOUTZRvChpc/I0HpJ2Al6oLCozM+sYZY96+iLwS2CMpCuAtwGn\nVBWUmZl1joaJQpKAv5AuWrQ/qcvpjIhYWXFsZmbWARomiogISbMjYjfWXrTIzMw2EGXHKP5L0lsr\njcTMzDpS2TGK/YATJN0PPEvqfoqI2L2qwMzMrDOUTRT/UGkUZmbWsRpd4W4z4KPAzsCfgYsiYk1/\nBGZmZp2h0RjFpcBkUpI4DPhG5RGZmVlHadT1NCkf7YSki4A/VR+SmZl1kkYtildniHWXk5nZhqlR\nothD0lP59jSwe/d9SU812rikQyXdLWmxpM8XlDtaUkia3OwbMDOzahV2PUXEkFY3LGkIcAHwbmA5\nME9SV0Qsqis3DDgD+GOrr2VmZtUpe8JdK/YFFkfEkoh4EZgJHNVDuS8B5wLPVxiLmZm1qMpEMQpY\nVvN4eV72qnwd7jERUTg1iKRpkuZLmr9q1aN9H6mZmfWqykRRSNLrgPOAMxuVjYgZETE5IiYPH75t\n9cGZmdmrqkwUK4AxNY9H52XdhgG7AjflqUH2B7o8oG1m1lmqTBTzgAmSdpC0CXAc0NW9MiJWRcSI\niBgfEeOBW4ApETG/wpjMzKxJlSWKfN7F6cAc4C5gVkQslHSOpClVva6ZmfWtspMCtiQiZgOz65ad\n1UvZg6qMxczMWtO2wWwzMxsYnCjMzKyQE4WZmRVyojAzs0JOFGZmVsiJwszMCjlRmJlZIScKMzMr\n5ERhZmaFnCjMzKyQE4WZmRVyojAzs0JOFGZmVsiJwszMCjlRmJlZIScKMzMr5ERhZmaFnCjMzKyQ\nE4WZmRVyojAzs0JOFGZmVsiJwszMCjlRmJlZIScKMzMr5ERhZmaFnCjMzKyQE4WZmRVyojAzs0JO\nFGZmVsiJwszMCjlRmJlZIScKMzMrVGmikHSopLslLZb0+R7Wf1rSIkl3SLpe0rgq4zEzs+ZVligk\nDQEuAA4DJgFTJU2qK3YbMDkidgeuBr5WVTxmZtaaKlsU+wKLI2JJRLwIzASOqi0QETdGxOr88BZg\ndIXxmJlZC6pMFKOAZTWPl+dlvTkVuLanFZKmSZovaf6qVY/2YYhmZtZIRwxmSzoBmAx8vaf1ETEj\nIiZHxOThw7ft3+DMzDZwG1W47RXAmJrHo/Oy15B0MPCvwIER8UKF8ZiZWQuqbFHMAyZI2kHSJsBx\nQFdtAUl7ARcCUyLikQpjMTOzFlWWKCJiDXA6MAe4C5gVEQslnSNpSi72dWBL4CpJCyR19bI5MzNr\nkyq7noiI2cDsumVn1dw/uMrXNzOz9dcRg9lmZta5nCjMzKyQE4WZmRVyojAzs0JOFGZmVsiJwszM\nCjlRmJlZIScKMzMr5ERhZmaFnCjMzKyQE4WZmRVyojAzs0JOFGZmVsiJwszMCjlRmJlZIScKMzMr\n5ERhZmaFnCjMzKyQE4WZmRVyojAzs0JOFGZmVsiJwszMCjlRmJlZIScKMzMr5ERhZmaFnCjMzKyQ\nE4WZmRVyojAzs0JOFGZmVsiJwszMCjlRmJlZIScKMzMr5ERhZmaFKk0Ukg6VdLekxZI+38P6TSX9\nOK//o6TxVcZjZmbNqyxRSBoCXAAcBkwCpkqaVFfsVOCJiNgZ+CZwblXxmJlZa6psUewLLI6IJRHx\nIjATOKquzFHApfn+1cC7JKnCmMzMrEkbVbjtUcCymsfLgf16KxMRayStAt4ArKwtJGkaMC0/emny\n5NffX0nEA84Lw2HTVe2OojO4LtZyXazluljrqdGtPrPKRNFnImIGMANA0vyIJya3OaSOkOpitesC\n10Ut18Varou1JM1v9blVdj2tAMbUPB6dl/VYRtJGwHDgsQpjMjOzJlWZKOYBEyTtIGkT4Digq65M\nF3Byvv9+4IaIiApjMjOzJlXW9ZTHHE4H5gBDgIsjYqGkc4D5EdEFXARcJmkx8DgpmTQyo6qYByDX\nxVqui7VcF2u5LtZquS7kHXgzMyviM7PNzKyQE4WZmRXq2ETh6T/WKlEXn5a0SNIdkq6XNK4dcfaH\nRnVRU+5oSSFp0B4aWaYuJB2T/zcWSvpRf8fYX0p8R8ZKulHSbfl7cng74qyapIslPSLpzl7WS9K3\ncj3dIWnvUhuOiI67kQa/7wV2BDYBbgcm1ZX5OPC9fP844MftjruNdfEOYIt8/2Mbcl3kcsOAucAt\nwOR2x93G/4sJwG3A6/Pjke2Ou411MQP4WL4/Cbi/3XFXVBdvB/YG7uxl/eHAtYCA/YE/ltlup7Yo\nPP3HWg3rIiJujIjV+eEtpHNWBqMy/xcAXyLNG/Z8fwbXz8rUxWnABRHxBEBEPNLPMfaXMnURwFb5\n/nDgwX6Mr99ExFzSEaS9OQr4YSS3AFtLelOj7XZqouhp+o9RvZWJiDVA9/Qfg02Zuqh1KmmPYTBq\nWBe5KT0mIn7Rn4G1QZn/i4nAREm/k3SLpEP7Lbr+VaYupgMnSFoOzAY+2T+hdZxmf0+AATKFh5Uj\n6QRgMnBgu2NpB0mvA84DTmlzKJ1iI1L300GkVuZcSbtFxJNtjao9pgKXRMQ3JB1AOn9r14h4pd2B\nDQSd2qLw9B9rlakLJB0M/CswJSJe6KfY+lujuhgG7ArcJOl+Uh9s1yAd0C7zf7Ec6IqIlyLiPuAe\nUuIYbMrUxanALICI+AOwGTCiX6LrLKV+T+p1aqLw9B9rNawLSXsBF5KSxGDth4YGdRERqyJiRESM\nj4jxpPGaKRHR8mRoHazMd+RnpNYEkkaQuqKW9GeQ/aRMXTwAvAtA0ltIieLRfo2yM3QBJ+Wjn/YH\nVkXEQ42e1JFdT1Hd9B8DTsm6+DqwJXBVHs9/ICKmtC3oipSsiw1CybqYAxwiaRHwMvDZiBh0re6S\ndXEm8H1J/0wa2D5lMO5YSrqStHMwIo/HfBHYGCAivkcanzkcWAysBj5UaruDsK7MzKwPdWrXk5mZ\ndQgnCjMzK+REYWZmhZwozMyskBOFmZkVcqIwqyPpZUkLJN0p6eeStu7j7Z8i6dv5/nRJn+nL7Zv1\nNScKs3U9FxF7RsSupHN0PtHugMzayYnCrNgfqJk0TdJnJc3Lc/mfXbP8pLzsdkmX5WVH5mul3Cbp\nOknbtSF+s/XWkWdmm3UCSUNI0z5clB8fQporaV/SfP5dkt5OmmPsC8DfRsRKSdvkTfwW2D8iQtI/\nAp8jnSFsNqA4UZita3NJC0gtibuAX+flh+TbbfnxlqTEsQdwVUSsBIiI7usBjAZ+nOf73wS4r3/C\nN+tb7noyW9dzEbEnMI7UcugeoxDwlTx+sWdE7BwRFxVs5/8C346I3YCPkCaiMxtwnCjMepGvGvhP\nwJl5Kvs5wIclbQkgaZSkkcANwAckvSEv7+56Gs7aKZxPxmyActeTWYGIuE3SHcDUiLgsT1H9hzxL\n7zPACXmm0i8DN0t6mdQ1dQrpqmpXSXqClEx2aMd7MFtfnj3WzMwKuevJzMwKOVGYmVkhJwozMyvk\nRGFmZoWcKMzMrJAThZmZFXKiMDOzQv8fCfGCx00sEnYAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_7hROIkaJzR",
        "colab_type": "code",
        "outputId": "7ad73d43-43f9-47a2-ddaf-a55e316dd47a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        }
      },
      "source": [
        "thresholds"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.20078869, -0.18029058, -0.15043726, -0.14958466, -0.12733462,\n",
              "       -0.1142941 , -0.09281931, -0.08794601, -0.08258102, -0.07007139,\n",
              "       -0.06386267, -0.04914839, -0.04536122, -0.03991278,  0.0032915 ,\n",
              "        0.01213433,  0.02619439,  0.03145977,  0.04871897,  0.0515638 ,\n",
              "        0.06493837,  0.065023  ,  0.09898417,  0.11549516,  0.12179099,\n",
              "        0.12585371,  0.16106135,  0.1906223 ,  0.20018683,  0.20105976,\n",
              "        0.22408591,  0.22931596,  0.24693291,  0.26336904,  0.27523711,\n",
              "        0.30423874,  0.31364573,  0.39424539,  0.40148935,  0.42411536,\n",
              "        0.42593404,  0.49589616])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7WKmxic26C8",
        "colab_type": "text"
      },
      "source": [
        "## Your turn\n",
        "\n",
        "Try to generate ROC curves for your dataset and algorithm, and find a cutoff point with the best threshold. \n",
        "\n",
        "Even if your dataset is balanced, plot precision-recall curves as well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HW1CtmsaKZl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}